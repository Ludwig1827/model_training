{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1XDORChpjXmQONQjMWAzrpy06mX8iPcIu","authorship_tag":"ABX9TyMdBxwXSsTjbn6mZ2bTly06"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b38d050cbb2243d9bf5c66b00ca998f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3559155c0d5a47c99e422bc3db02757c","IPY_MODEL_0200fa612463437d81af6f66ef7408ed","IPY_MODEL_9ebc63e25855403bb2ef811530f38519"],"layout":"IPY_MODEL_7c622b56841b4b0dbee90690834caa58"}},"3559155c0d5a47c99e422bc3db02757c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38622257750d4ca1bdc00d277edc5466","placeholder":"​","style":"IPY_MODEL_6805f146ff04474488b7d702798cdac9","value":"Map: 100%"}},"0200fa612463437d81af6f66ef7408ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_919bcfef436d4802afe10ea68a13bce2","max":113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d5aa69a166f41a09d9d4d306729ccc1","value":113}},"9ebc63e25855403bb2ef811530f38519":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f26532934db4f5383c934fc2a815cca","placeholder":"​","style":"IPY_MODEL_c6ce40785cc74fa095bce3a6d06e462e","value":" 113/113 [00:00&lt;00:00, 3980.99 examples/s]"}},"7c622b56841b4b0dbee90690834caa58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38622257750d4ca1bdc00d277edc5466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6805f146ff04474488b7d702798cdac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"919bcfef436d4802afe10ea68a13bce2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5aa69a166f41a09d9d4d306729ccc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f26532934db4f5383c934fc2a815cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ce40785cc74fa095bce3a6d06e462e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4686b91547434b84a9d308d34dbd9e42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93bf8f0835ab4075b7a9a44df905eaff","IPY_MODEL_6aa4048214c1495ea641b0a1a39930c5","IPY_MODEL_c18c08fba05c4336a2750390f1b30417"],"layout":"IPY_MODEL_10968d9fc64d4b70850fc2eec1b9c3ab"}},"93bf8f0835ab4075b7a9a44df905eaff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e08fd3b4cce1441ab518f0c7610a8de4","placeholder":"​","style":"IPY_MODEL_caed2e84c2944da8bb52a667844fe7a4","value":"Extracting prompt in train dataset: 100%"}},"6aa4048214c1495ea641b0a1a39930c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49dd2e4945ca4ea0b565e343068d9d12","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc1b99ab1e324dfc8bbabc67e82b1805","value":90}},"c18c08fba05c4336a2750390f1b30417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_652e6782540e40879b8afe3f462956d4","placeholder":"​","style":"IPY_MODEL_ebeb364edb794e8ea649efe027609014","value":" 90/90 [00:00&lt;00:00, 2976.02 examples/s]"}},"10968d9fc64d4b70850fc2eec1b9c3ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e08fd3b4cce1441ab518f0c7610a8de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caed2e84c2944da8bb52a667844fe7a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49dd2e4945ca4ea0b565e343068d9d12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc1b99ab1e324dfc8bbabc67e82b1805":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"652e6782540e40879b8afe3f462956d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebeb364edb794e8ea649efe027609014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c026854eba364cdd99d42b78b98da8e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9992f5e5c3c349f1bae06099500ae975","IPY_MODEL_a312d72c73ac4905821dc1e8b84a8fd0","IPY_MODEL_e93fc7dfa0304458bf9b2b1d29c73d73"],"layout":"IPY_MODEL_ef6f0b14c5f44d06a6725397d5d44e93"}},"9992f5e5c3c349f1bae06099500ae975":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e94b4907a6224dbf8c38ac3a8d7d80a2","placeholder":"​","style":"IPY_MODEL_548b8fdb29c94c59a1dd50c9b3135e34","value":"Applying chat template to train dataset: 100%"}},"a312d72c73ac4905821dc1e8b84a8fd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36381d273eb343aca5a7432a0f989b36","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82425d6809564568840a437a94297918","value":90}},"e93fc7dfa0304458bf9b2b1d29c73d73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd0eef2aa3044ad8b2fa767afedd2f3f","placeholder":"​","style":"IPY_MODEL_5a07e78de4ba49e8ab782fa6774f3853","value":" 90/90 [00:00&lt;00:00, 3420.23 examples/s]"}},"ef6f0b14c5f44d06a6725397d5d44e93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e94b4907a6224dbf8c38ac3a8d7d80a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"548b8fdb29c94c59a1dd50c9b3135e34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36381d273eb343aca5a7432a0f989b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82425d6809564568840a437a94297918":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd0eef2aa3044ad8b2fa767afedd2f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a07e78de4ba49e8ab782fa6774f3853":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e6bb45e4df24da2bde7d47eba1e4f9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18cadf155df44fe2bf240e7cecc53544","IPY_MODEL_c248dc2cedba4c20b0b63a4413a9e506","IPY_MODEL_da21128e9ef046b8a3c5088a9867a3a9"],"layout":"IPY_MODEL_aa44aab7b95145bc84969637dff1dcc9"}},"18cadf155df44fe2bf240e7cecc53544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c805266674846d7b306a68f83c1166d","placeholder":"​","style":"IPY_MODEL_10ba98c91092470eaa49e7b5f3896c16","value":"Tokenizing train dataset: 100%"}},"c248dc2cedba4c20b0b63a4413a9e506":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7ae3beb3e5243f1a42846cd36d28c15","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a695787bd54b8ba2346ca54678faa8","value":90}},"da21128e9ef046b8a3c5088a9867a3a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ca8b60b103442c1ab6e34e0f5dcc7cb","placeholder":"​","style":"IPY_MODEL_c264f11cc9184310812097ae6e3c0c98","value":" 90/90 [00:00&lt;00:00, 413.73 examples/s]"}},"aa44aab7b95145bc84969637dff1dcc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c805266674846d7b306a68f83c1166d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ba98c91092470eaa49e7b5f3896c16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7ae3beb3e5243f1a42846cd36d28c15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a695787bd54b8ba2346ca54678faa8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ca8b60b103442c1ab6e34e0f5dcc7cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c264f11cc9184310812097ae6e3c0c98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a230a5da83b4867ae5f7c7eab0d486c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d9b380ed41340f48665e957b6402a74","IPY_MODEL_9221e40b7edb4cee9ba749f5ab896869","IPY_MODEL_886812a6183349e5ae7454a97b9161dc"],"layout":"IPY_MODEL_12967160e7dc479aa7e1dbb934d3ce8d"}},"6d9b380ed41340f48665e957b6402a74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd2a1c4977d24b8ca5458d2eed221f81","placeholder":"​","style":"IPY_MODEL_5a208d61c06b4bd19015321096ec4789","value":"Extracting prompt in eval dataset: 100%"}},"9221e40b7edb4cee9ba749f5ab896869":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c40e31d8972401fb2de355bd4cc8250","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90616dcdc5e7402e9c7812a46336d5f0","value":23}},"886812a6183349e5ae7454a97b9161dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fce6d2ae6f41415aad80c16f556a83e3","placeholder":"​","style":"IPY_MODEL_4bdbfbb3ff904645a02cbe95e4c5e55e","value":" 23/23 [00:00&lt;00:00, 1122.78 examples/s]"}},"12967160e7dc479aa7e1dbb934d3ce8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd2a1c4977d24b8ca5458d2eed221f81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a208d61c06b4bd19015321096ec4789":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c40e31d8972401fb2de355bd4cc8250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90616dcdc5e7402e9c7812a46336d5f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fce6d2ae6f41415aad80c16f556a83e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bdbfbb3ff904645a02cbe95e4c5e55e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa9c43bb014f4652ac58a6b48ed5cd77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4556b159d5204f8da2e8e86c8e78b6e4","IPY_MODEL_2c0184c8748545eead4216426fdad6fa","IPY_MODEL_e6b9ea18c3864f1c9ea70e562b78f884"],"layout":"IPY_MODEL_c80ffd24b3be45f5bec74988285f96c8"}},"4556b159d5204f8da2e8e86c8e78b6e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc0b4622fb564a6fad606f080f7ec237","placeholder":"​","style":"IPY_MODEL_a46d031ebfaa48dbb695576420abe056","value":"Applying chat template to eval dataset: 100%"}},"2c0184c8748545eead4216426fdad6fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c1821ba3a1494babd6711eabea4d51","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_526a88fc2fbe4b989461309727473d00","value":23}},"e6b9ea18c3864f1c9ea70e562b78f884":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a80ed3732c3446eb7b667297bd267df","placeholder":"​","style":"IPY_MODEL_5cec40722d174c97a1443ed4fd9063d6","value":" 23/23 [00:00&lt;00:00, 1370.98 examples/s]"}},"c80ffd24b3be45f5bec74988285f96c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc0b4622fb564a6fad606f080f7ec237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a46d031ebfaa48dbb695576420abe056":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3c1821ba3a1494babd6711eabea4d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526a88fc2fbe4b989461309727473d00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a80ed3732c3446eb7b667297bd267df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cec40722d174c97a1443ed4fd9063d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed9bcb218707423187f3ff982b63ea96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6083c7a6908403dadb2ad23fd4e40c1","IPY_MODEL_c1186dba79fc41b4afe40cb0832ca6c1","IPY_MODEL_4b386ae263e14cb68d4ff849335f1c02"],"layout":"IPY_MODEL_87bdfd96d8fb4efdbb4f30fd21994e17"}},"f6083c7a6908403dadb2ad23fd4e40c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf3e638c05448de9937119d35632ff6","placeholder":"​","style":"IPY_MODEL_574b606e01a74bd8b10704e2ccb1ca85","value":"Tokenizing eval dataset: 100%"}},"c1186dba79fc41b4afe40cb0832ca6c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fef597fb9174b86ad2821fc1e75f0cb","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c52032a3a5fa4761a5606e32e80d33ec","value":23}},"4b386ae263e14cb68d4ff849335f1c02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebacbc24a9594cca98eb6774c2d23d96","placeholder":"​","style":"IPY_MODEL_e65ad15433894646a1d0eefbaee6199d","value":" 23/23 [00:00&lt;00:00, 368.21 examples/s]"}},"87bdfd96d8fb4efdbb4f30fd21994e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf3e638c05448de9937119d35632ff6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"574b606e01a74bd8b10704e2ccb1ca85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fef597fb9174b86ad2821fc1e75f0cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52032a3a5fa4761a5606e32e80d33ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebacbc24a9594cca98eb6774c2d23d96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e65ad15433894646a1d0eefbaee6199d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Relevant packages"],"metadata":{"id":"BndX4GD5otZf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UJjxrR1on94"},"outputs":[],"source":["%%capture\n","# Normally using pip install unsloth is enough\n","\n","# Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n","# Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n","!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n","!pip install --no-deps cut_cross_entropy unsloth_zoo\n","!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n","!pip install --no-deps unsloth"]},{"cell_type":"code","source":["# Modules for fine-tuning\n","from unsloth import FastLanguageModel\n","import torch # Import PyTorch\n","from trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\n","from unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n","# Hugging Face modules\n","from huggingface_hub import login # Lets you login to API\n","from transformers import TrainingArguments # Defines training hyperparameters\n","from datasets import load_dataset # Lets you load fine-tuning datasets\n","# Import weights and biases\n","import wandb\n"],"metadata":{"id":"PvRuXSATo0Kc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## API keys"],"metadata":{"id":"OyRjp-nCpJUW"}},{"cell_type":"code","source":["# Initialize Hugging Face & WnB tokens\n","hugging_face_token = \"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\"\n","wnb_token = \"74e1599fd25989e53e27f4d82a7447f0c0aecb01\"\n","\n","# Login to Hugging Face\n","login(hugging_face_token) # from huggingface_hub import login\n","\n","# Login to WnB\n","wandb.login(key=wnb_token) # import wandb\n","run = wandb.init(\n","    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset_YouTube Walkthrough',\n","    job_type=\"training\",\n","    anonymous=\"allow\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"TM7qWT47pA8h","executionInfo":{"status":"ok","timestamp":1739215381401,"user_tz":360,"elapsed":2554,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"2683eb6e-c752-47b6-ab4a-35c8ec63093c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250210_192259-edvvw6l0</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/edvvw6l0?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">whole-energy-16</a></strong> to <a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/edvvw6l0?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/edvvw6l0?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Do NOT share these links with anyone. They can be used to claim your runs."]},"metadata":{}}]},{"cell_type":"markdown","source":["## Load the basic model (deepseek-r1)\n"],"metadata":{"id":"HKd6OwokpPzi"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer\n","from peft import PeftModel\n","from unsloth import FastLanguageModel  # Unsloth for fast inference\n","\n","# Define model paths\n","base_model_path = \"drive/MyDrive/deepseek-r1\"  # Change to your base model\n","lora_model_path = \"drive/MyDrive/fine-tuned-deepseek-r1-with-reasoning-0.01\"\n","tokenizer_path = \"drive/MyDrive/tokenizer-deepseek-r1-with-reasoning-0.01\"\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n","\n","# Load the base model optimized with Unsloth\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=base_model_path,\n","    max_seq_length=4096,  # Adjust based on model capability\n","    dtype=torch.float16,\n","    load_in_4bit=True,  # Enable quantization for efficiency\n",")\n","\n","# Load LoRA adapter correctly\n","model = PeftModel.from_pretrained(model, lora_model_path)\n","\n","# Optimize LoRA model for inference (2x faster with Unsloth)\n","FastLanguageModel.for_inference(model)\n","\n","# Move model to GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_arRkdL5uzG","executionInfo":{"status":"ok","timestamp":1739215400326,"user_tz":360,"elapsed":15688,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"0a806a99-8ec7-4f3e-d4a5-593e968c8587"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Model loaded successfully!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight']\n","  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"]}]},{"cell_type":"code","source":["model.save_pretrained(\"drive/MyDrive/fine-tuned-deepseek-r1\")"],"metadata":{"id":"o3zUdGJPSvmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = \"drive/MyDrive/fine-tuned-deepseek-r1\""],"metadata":{"id":"EH0rtN0DUko4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n","\n","# Load the base model optimized with Unsloth\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name= model_name,\n","    max_seq_length=4096,  # Adjust based on model capability\n","    dtype=torch.float16,\n","    load_in_4bit=True,  # Enable quantization for efficiency\n",")\n","\n","# Optimize LoRA model for inference (2x faster with Unsloth)\n","FastLanguageModel.for_inference(model)\n","\n","# Move model to GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zSK5kGdUVMF","executionInfo":{"status":"ok","timestamp":1739215551913,"user_tz":360,"elapsed":15636,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"0510c68a-31c1-46ae-ead0-bdf4a4f9bd14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight']\n","  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["# Define a system prompt under prompt_style\n","prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n","Write a response that appropriately completes the request.\n","Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n","\n","### Instruction:\n","You are a customer service representative with advanced knowledge of water filtration systems, troubleshooting, and warranty replacements. Please answer the following customer inquiry professionally and helpfully.\n","\n","### Question:\n","{}\n","\n","### Response:\n","<think>{}\"\"\""],"metadata":{"id":"NOde_jko6W73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the input question and prompt format\n","question = '''Hi there,\n","\n","I just purchased the iSpring RO System RCC7 and the leak stop valve is faulty - the reservoir will not stay on. Can you please send me a replacement? My address is as follows:\n","\n","232 Hay Ave\n","St. Andrews, MB\n","R1A 3M7\n","Canada\n","\n","Thank you,\n","\n","Ashley Krahn\n","\n","Ph: (204) 481-2200\n","ashleykrahn@outlook.com?'''\n","\n","\n","# Tokenize input\n","inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(device)\n","\n","# Generate response\n","outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=2048)\n","\n","# Decode output\n","response = tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[1].strip()\n","\n","print(\"Model's Response:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrBD8_-H6Ocq","executionInfo":{"status":"ok","timestamp":1739215599884,"user_tz":360,"elapsed":37591,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"e4c7d439-7f21-42c6-bd73-4c29b8c2bc64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model's Response: <think>\n","Alright, so I need to help Ashley with her iSpring RO System issue. Let me start by understanding the problem. She mentioned that the leak stop valve is faulty, causing the reservoir not to stay on. Hmm, that sounds like a common issue, but I need to figure out the best way to assist her.\n","\n","First, I should acknowledge her purchase and the problem she's facing. It's important to be empathetic, so I'll make sure my response is kind and supportive. I should thank her for reaching out and assure her that I can help.\n","\n","Next, I need to address the faulty leak stop valve. I recall that iSpring has replacement parts available, so I should check if the leak stop valve is something that can be easily replaced. Maybe I should guide her through a quick fix or suggest ordering the replacement part.\n","\n","Wait, she's in Canada, so I should confirm if the warranty covers this part. iSpring's warranty typically covers defects, but I'm not sure if the leak stop valve falls under that. I'll need to check the warranty terms or suggest she contacts iSpring directly for warranty information.\n","\n","If the warranty doesn't cover it, I can offer her the option to purchase the replacement part from iSpring's website or an authorized dealer. I'll also provide her with the necessary information to find the right part, maybe a part number or model reference.\n","\n","Additionally, I should include the shipping details she provided to make sure everything goes smoothly. Maybe I'll ask for her phone number to confirm delivery or if she prefers to handle it another way.\n","\n","Wait, she included her email and phone number. Should I add that to the response? Maybe, but I should be cautious with personal information. It's better to ask for necessary details to assist her without sharing her info publicly.\n","\n","I should also make sure the response is clear and concise, avoiding any technical jargon that might confuse her. Keeping it professional yet approachable is key.\n","\n","Putting it all together, I'll start with a greeting, acknowledge the issue, confirm the part replacement, check the warranty, provide purchase options, and include her contact details. That should cover everything she needs to resolve the problem.\n","</think>\n","\n","Subject: Assistance with iSpring RO System RCC7\n","\n","Dear Ashley,\n","\n","Thank you for reaching out and for purchasing the iSpring RO System RCC7. I understand the issue you're experiencing with the leak stop valve, and I'm here to help.\n","\n","The leak stop valve is indeed a replaceable part, and I can assist you with the replacement. To ensure the reservoir stays on, I recommend ordering the replacement part from the manufacturer's website or an authorized dealer.\n","\n","Please provide your phone number so I can confirm the details for your order. If you prefer, you can also contact iSpring directly for warranty information, as they may cover this part under your warranty.\n","\n","Looking forward to helping you get it fixed.\n","\n","Best regards,  \n","[Your Name]  \n","Customer Service Representative  \n","[Your Contact Information]<｜end▁of▁sentence｜>\n"]}]},{"cell_type":"markdown","source":["## DPO_trainer"],"metadata":{"id":"2_rE704GqU7F"}},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"8L8IiCfWqXJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load CSV file\n","file_path = \"drive/MyDrive/RLHF.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Select relevant columns\n","df = df[['Model', 'CUSTOMER_QUESTION', 'AI_ANSWER', 'LAURENCE_ANSWER']]\n","\n","# Combine Model name with Customer Question\n","df[\"prompt\"] = df.apply(lambda row: f\"Product Name: {row['Model']} | {row['CUSTOMER_QUESTION']}\", axis=1)\n","\n","# Drop original columns\n","df.drop(columns=['Model', 'CUSTOMER_QUESTION'], inplace=True)\n","\n","# Rename columns to match dataset format\n","train_df = df.rename(columns={\"AI_ANSWER\": \"rejected\", \"LAURENCE_ANSWER\": \"chosen\"})\n","\n","train_df.dropna(inplace=True)\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_df)\n","\n","# Create a dataset dictionary (for Hugging Face format)\n","dataset = DatasetDict({\n","    \"train\": train_dataset\n","})\n","\n","dataset = dataset.map(lambda x: x, remove_columns=[\"__index_level_0__\"])\n","\n","# Display dataset info\n","print(dataset)\n"],"metadata":{"id":"x9nAnIz4qn89","colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["b38d050cbb2243d9bf5c66b00ca998f9","3559155c0d5a47c99e422bc3db02757c","0200fa612463437d81af6f66ef7408ed","9ebc63e25855403bb2ef811530f38519","7c622b56841b4b0dbee90690834caa58","38622257750d4ca1bdc00d277edc5466","6805f146ff04474488b7d702798cdac9","919bcfef436d4802afe10ea68a13bce2","0d5aa69a166f41a09d9d4d306729ccc1","0f26532934db4f5383c934fc2a815cca","c6ce40785cc74fa095bce3a6d06e462e"]},"executionInfo":{"status":"ok","timestamp":1739209318002,"user_tz":360,"elapsed":972,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"956eba18-697d-4058-f3df-a5b3e7b47899"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/113 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b38d050cbb2243d9bf5c66b00ca998f9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['rejected', 'chosen', 'prompt'],\n","        num_rows: 113\n","    })\n","})\n"]}]},{"cell_type":"code","source":["split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n","\n","# Create a new DatasetDict with separate train and test sets\n","dataset = DatasetDict({\n","    \"train\": split_dataset[\"train\"],\n","    \"test\": split_dataset[\"test\"]\n","})"],"metadata":{"id":"_VS86fzrqrQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add special tokens if necessary\n","tokenizer.pad_token = tokenizer.eos_token\n","model.config.pad_token_id = model.config.eos_token_id\n","\n","# Define the maximum length\n","max_length = 1024"],"metadata":{"id":"bRPYO5ptqt_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_res = lambda dataset, split, res: [\n","    \"\\n\\nHuman: \" + prompt + \"\\n\\nAssistant: \" + resp\n","    for prompt, resp in zip(dataset[split][\"prompt\"], dataset[split][res])\n","]\n","\n","# Extract from training set\n","chosen_samples_train = get_res(dataset, \"train\", \"chosen\")\n","rejected_samples_train = get_res(dataset, \"train\", \"rejected\")\n","\n","# Extract from test set\n","chosen_samples_test = get_res(dataset, \"test\", \"chosen\")\n","rejected_samples_test = get_res(dataset, \"test\", \"rejected\")\n","\n","# Print examples\n","print('Chosen (Train):', chosen_samples_train[0])\n","print('Rejected (Train):', rejected_samples_train[0])\n","print('Chosen (Test):', chosen_samples_test[0])\n","print('Rejected (Test):', rejected_samples_test[0])\n"],"metadata":{"id":"46VClzwFqxI7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739209337272,"user_tz":360,"elapsed":26,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"2a44268d-a64e-4c60-8d0e-96b28d8f98e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chosen (Train): \n","\n","Human: Product Name: WSP50ARB | I am looking for a sediment filter to catch the sediment leaving my tankless water heater. Will this filter withstand the 120 degree setting? \r\n","Sent from my iPhone\n","\n","Assistant: Hi Tom,\r\n","\r\n","The WSP50ARB model is not designed for hot water applications. The maximum water temperature that the filter can withstand is 100 F (37.8 C). We recommend installing the spin down sediment filter prior your water heater to act as a pre-filter that would catch sediments and protect your water heater. \r\n","\r\n","If you have other questions or concerns, please don't hesitate to contact us.\r\n","\r\n","Best,\r\n","\r\n","iSpring Customer Support\n","Rejected (Train): \n","\n","Human: Product Name: WSP50ARB | I am looking for a sediment filter to catch the sediment leaving my tankless water heater. Will this filter withstand the 120 degree setting? \r\n","Sent from my iPhone\n","\n","Assistant: Dear customer, Thank you for reaching out to iSpring Water Systems. We appreciate your interest in our products and we are here to assist you. Regarding your query about the iSpring WSP50ARB sediment filter, we would like to inform you that this filter is not specifically designed for use with hot water. It is recommended to install this filter before your water heater, as it is not intended for hot water purposes. The filter is designed to protect your plumbing system and appliances from sediment, rust, dirt, sand, and large particles down to 50 microns. If you are looking for a sediment filter that can withstand the 120-degree setting of your tankless water heater, we recommend considering a different model specifically designed for hot water applications. Unfortunately, we do not have a specific model available for this purpose. If you have any further questions or need assistance with any other products, please feel free to let us know. We are here to help. Best regards, iSpring Water Systems Customer Support\n","Chosen (Test): \n","\n","Human: Product Name: WSP50ARB | Hello,\r\n","\r\n","I installed this spin down filter and it was working fine until my family noticed significant reduction in water pressure. Our system is set to 60psi and during regular use it would drop to 30-35 psi after the WSP50ARB filter. I bypassed the filter and the water pressure returns to normal. I tried to clean the filter and backwash it but it doesn't help. I see the filter screen has a layer of sediment that doesn't backwash out no matter the duration or amount of backwashing I do. Can you please help with any suggestions?\r\n","\r\n","Thank you\n","\n","Assistant: Hi Chatchai,\r\n","\r\n","If you're having trouble with frequent clogging, we recommend trying a larger filter mesh size. The key is finding the balance between clogging frequency and filtration. I can send you a replacement 100-micron filter cartridge for you to try and see if the clogging is alleviated. Please send a copy of your purchase receipt along with your shipping address, and I'll arrange to send you the replacement FWSP100ARB filter cartridge.\r\n","\r\n","Please let me know if you have any questions or concerns.\r\n","\r\n","Best,\r\n","\r\n","iSpring Customer Support\n","Rejected (Test): \n","\n","Human: Product Name: WSP50ARB | Hello,\r\n","\r\n","I installed this spin down filter and it was working fine until my family noticed significant reduction in water pressure. Our system is set to 60psi and during regular use it would drop to 30-35 psi after the WSP50ARB filter. I bypassed the filter and the water pressure returns to normal. I tried to clean the filter and backwash it but it doesn't help. I see the filter screen has a layer of sediment that doesn't backwash out no matter the duration or amount of backwashing I do. Can you please help with any suggestions?\r\n","\r\n","Thank you\n","\n","Assistant: Hello, Thank you for reaching out to iSpring Water Systems with your concern about the WSP50ARB spin down filter. We apologize for any inconvenience this may have caused and we are here to assist you. Based on the information you provided, it seems that there is a buildup of sediment in the filter screen, causing a reduction in water pressure. To resolve this issue, we recommend the following steps: 1. Ensure that the filter is properly installed and there are no leaks or loose connections. 2. Try cleaning the filter screen again, following the cleaning instructions provided in the user manual. 3. If cleaning the filter screen does not improve the water pressure, it is possible that the filter screen may be damaged or worn out. In this case, we recommend replacing the filter screen. To assist you further, we kindly request that you provide us with a copy of your purchase receipt and any attached pictures or videos of the issue. This will help us determine if the product is still under warranty and allow us to send you a replacement part if necessary. If the product is not under warranty, you can also order a replacement filter from our website. Please email the purchase receipt and any media files to support@123filter.com. Once we have received the necessary information, we will confirm the warranty status and arrange for a replacement part to be sent to you. If you have not provided your shipping address in the query, please provide it to us so that we can ensure the replacement part is sent to the correct location. We apologize for any inconvenience caused and appreciate your patience. Please let us know if there is anything else we can assist you with. Thank you. Best regards, iSpring Water Systems Customer Support\n"]}]},{"cell_type":"code","source":["# Set parameters\n","max_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\n","dtype = None # Set to default\n","load_in_4bit = True # Enables 4 bit quantization — a memory saving optimization\n","\n","# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n","    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n","    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n","    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n","    token=hugging_face_token, # Use hugging face token\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSO0C-4d9qkK","executionInfo":{"status":"ok","timestamp":1739209586731,"user_tz":360,"elapsed":12332,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"6538f739-45ee-4ff3-e876-bea8c5c5ba94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 64,\n","    lora_dropout = 0, # Currently only supports dropout = 0\n","    bias = \"none\",    # Currently only supports bias = \"none\"\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"],"metadata":{"id":"8VxJEr2Oqy-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One must patch the DPO Trainer first!\n","from unsloth import PatchDPOTrainer\n","PatchDPOTrainer()"],"metadata":{"id":"nqht4yqJq1SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","from trl import DPOTrainer, DPOConfig\n","from unsloth import is_bfloat16_supported\n","\n","dpo_trainer = DPOTrainer(\n","    model = model,\n","    ref_model = None,\n","    args = DPOConfig(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_ratio = 0.1,\n","        num_train_epochs = 3,\n","        learning_rate = 5e-6,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.0,\n","        lr_scheduler_type = \"linear\",\n","        seed = 42,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n","    beta = 0.1,\n","    train_dataset = dataset[\"train\"],\n","    eval_dataset = dataset[\"test\"],\n","    tokenizer = tokenizer,\n","    max_length = 2048,\n","    max_prompt_length = 1024,\n",")"],"metadata":{"id":"UKgtf1eVq4Ci","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["4686b91547434b84a9d308d34dbd9e42","93bf8f0835ab4075b7a9a44df905eaff","6aa4048214c1495ea641b0a1a39930c5","c18c08fba05c4336a2750390f1b30417","10968d9fc64d4b70850fc2eec1b9c3ab","e08fd3b4cce1441ab518f0c7610a8de4","caed2e84c2944da8bb52a667844fe7a4","49dd2e4945ca4ea0b565e343068d9d12","bc1b99ab1e324dfc8bbabc67e82b1805","652e6782540e40879b8afe3f462956d4","ebeb364edb794e8ea649efe027609014","c026854eba364cdd99d42b78b98da8e4","9992f5e5c3c349f1bae06099500ae975","a312d72c73ac4905821dc1e8b84a8fd0","e93fc7dfa0304458bf9b2b1d29c73d73","ef6f0b14c5f44d06a6725397d5d44e93","e94b4907a6224dbf8c38ac3a8d7d80a2","548b8fdb29c94c59a1dd50c9b3135e34","36381d273eb343aca5a7432a0f989b36","82425d6809564568840a437a94297918","dd0eef2aa3044ad8b2fa767afedd2f3f","5a07e78de4ba49e8ab782fa6774f3853","2e6bb45e4df24da2bde7d47eba1e4f9c","18cadf155df44fe2bf240e7cecc53544","c248dc2cedba4c20b0b63a4413a9e506","da21128e9ef046b8a3c5088a9867a3a9","aa44aab7b95145bc84969637dff1dcc9","9c805266674846d7b306a68f83c1166d","10ba98c91092470eaa49e7b5f3896c16","d7ae3beb3e5243f1a42846cd36d28c15","64a695787bd54b8ba2346ca54678faa8","4ca8b60b103442c1ab6e34e0f5dcc7cb","c264f11cc9184310812097ae6e3c0c98","5a230a5da83b4867ae5f7c7eab0d486c","6d9b380ed41340f48665e957b6402a74","9221e40b7edb4cee9ba749f5ab896869","886812a6183349e5ae7454a97b9161dc","12967160e7dc479aa7e1dbb934d3ce8d","bd2a1c4977d24b8ca5458d2eed221f81","5a208d61c06b4bd19015321096ec4789","5c40e31d8972401fb2de355bd4cc8250","90616dcdc5e7402e9c7812a46336d5f0","fce6d2ae6f41415aad80c16f556a83e3","4bdbfbb3ff904645a02cbe95e4c5e55e","aa9c43bb014f4652ac58a6b48ed5cd77","4556b159d5204f8da2e8e86c8e78b6e4","2c0184c8748545eead4216426fdad6fa","e6b9ea18c3864f1c9ea70e562b78f884","c80ffd24b3be45f5bec74988285f96c8","bc0b4622fb564a6fad606f080f7ec237","a46d031ebfaa48dbb695576420abe056","f3c1821ba3a1494babd6711eabea4d51","526a88fc2fbe4b989461309727473d00","1a80ed3732c3446eb7b667297bd267df","5cec40722d174c97a1443ed4fd9063d6","ed9bcb218707423187f3ff982b63ea96","f6083c7a6908403dadb2ad23fd4e40c1","c1186dba79fc41b4afe40cb0832ca6c1","4b386ae263e14cb68d4ff849335f1c02","87bdfd96d8fb4efdbb4f30fd21994e17","baf3e638c05448de9937119d35632ff6","574b606e01a74bd8b10704e2ccb1ca85","9fef597fb9174b86ad2821fc1e75f0cb","c52032a3a5fa4761a5606e32e80d33ec","ebacbc24a9594cca98eb6774c2d23d96","e65ad15433894646a1d0eefbaee6199d"]},"executionInfo":{"status":"ok","timestamp":1739209614028,"user_tz":360,"elapsed":1436,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"d340163f-c49c-41a7-d163-6018591fe1c0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Extracting prompt in train dataset:   0%|          | 0/90 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4686b91547434b84a9d308d34dbd9e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying chat template to train dataset:   0%|          | 0/90 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c026854eba364cdd99d42b78b98da8e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Tokenizing train dataset:   0%|          | 0/90 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6bb45e4df24da2bde7d47eba1e4f9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting prompt in eval dataset:   0%|          | 0/23 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a230a5da83b4867ae5f7c7eab0d486c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying chat template to eval dataset:   0%|          | 0/23 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9c43bb014f4652ac58a6b48ed5cd77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Tokenizing eval dataset:   0%|          | 0/23 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9bcb218707423187f3ff982b63ea96"}},"metadata":{}}]},{"cell_type":"code","source":["dpo_trainer.train()"],"metadata":{"id":"451JFI4Pq8R6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1739209738705,"user_tz":360,"elapsed":123081,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"589b98db-dfeb-41af-9881-7ede61225a1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 90 | Num Epochs = 3\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 33\n"," \"-____-\"     Number of trainable parameters = 167,772,160\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 01:53, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>rewards / chosen</th>\n","      <th>rewards / rejected</th>\n","      <th>rewards / accuracies</th>\n","      <th>rewards / margins</th>\n","      <th>logps / chosen</th>\n","      <th>logps / rejected</th>\n","      <th>logits / chosen</th>\n","      <th>logits / rejected</th>\n","      <th>eval_logits / chosen</th>\n","      <th>eval_logits / rejected</th>\n","      <th>nll_loss</th>\n","      <th>aux_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.693100</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-360.929047</td>\n","      <td>-428.916229</td>\n","      <td>-2.026259</td>\n","      <td>-2.234543</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.693100</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-372.489990</td>\n","      <td>-436.939636</td>\n","      <td>-2.118045</td>\n","      <td>-2.256978</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.687700</td>\n","      <td>0.008786</td>\n","      <td>-0.006173</td>\n","      <td>0.500000</td>\n","      <td>0.014959</td>\n","      <td>-390.776917</td>\n","      <td>-460.376801</td>\n","      <td>-2.075708</td>\n","      <td>-2.200300</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.672100</td>\n","      <td>0.002597</td>\n","      <td>-0.043691</td>\n","      <td>0.625000</td>\n","      <td>0.046288</td>\n","      <td>-365.703827</td>\n","      <td>-468.328247</td>\n","      <td>-2.073992</td>\n","      <td>-2.159647</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.651800</td>\n","      <td>0.077795</td>\n","      <td>-0.007141</td>\n","      <td>1.000000</td>\n","      <td>0.084936</td>\n","      <td>-407.119995</td>\n","      <td>-430.767639</td>\n","      <td>-1.946649</td>\n","      <td>-2.219787</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.603300</td>\n","      <td>0.055814</td>\n","      <td>-0.134859</td>\n","      <td>0.875000</td>\n","      <td>0.190672</td>\n","      <td>-338.845520</td>\n","      <td>-466.505249</td>\n","      <td>-2.116350</td>\n","      <td>-2.247275</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.564900</td>\n","      <td>0.102445</td>\n","      <td>-0.175393</td>\n","      <td>1.000000</td>\n","      <td>0.277839</td>\n","      <td>-384.916199</td>\n","      <td>-415.720123</td>\n","      <td>-2.148593</td>\n","      <td>-2.245431</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.503800</td>\n","      <td>0.145856</td>\n","      <td>-0.284649</td>\n","      <td>1.000000</td>\n","      <td>0.430505</td>\n","      <td>-339.108429</td>\n","      <td>-472.803772</td>\n","      <td>-1.995109</td>\n","      <td>-2.215102</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.469600</td>\n","      <td>0.181653</td>\n","      <td>-0.334493</td>\n","      <td>1.000000</td>\n","      <td>0.516146</td>\n","      <td>-367.608917</td>\n","      <td>-443.392090</td>\n","      <td>-2.109426</td>\n","      <td>-2.199303</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.407000</td>\n","      <td>0.220494</td>\n","      <td>-0.477100</td>\n","      <td>1.000000</td>\n","      <td>0.697595</td>\n","      <td>-439.130432</td>\n","      <td>-458.797363</td>\n","      <td>-2.070659</td>\n","      <td>-2.197767</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.343700</td>\n","      <td>0.281814</td>\n","      <td>-0.618930</td>\n","      <td>1.000000</td>\n","      <td>0.900745</td>\n","      <td>-437.461151</td>\n","      <td>-435.060333</td>\n","      <td>-2.075159</td>\n","      <td>-2.250862</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.075400</td>\n","      <td>0.405377</td>\n","      <td>-0.640482</td>\n","      <td>1.000000</td>\n","      <td>1.045859</td>\n","      <td>-279.093140</td>\n","      <td>-630.452393</td>\n","      <td>-2.088652</td>\n","      <td>-2.133168</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.245100</td>\n","      <td>0.444740</td>\n","      <td>-0.857211</td>\n","      <td>1.000000</td>\n","      <td>1.301951</td>\n","      <td>-356.331573</td>\n","      <td>-414.797760</td>\n","      <td>-2.013502</td>\n","      <td>-2.271331</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.226100</td>\n","      <td>0.500856</td>\n","      <td>-0.879448</td>\n","      <td>1.000000</td>\n","      <td>1.380304</td>\n","      <td>-445.183929</td>\n","      <td>-410.955811</td>\n","      <td>-2.068714</td>\n","      <td>-2.210360</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.174600</td>\n","      <td>0.618043</td>\n","      <td>-1.050382</td>\n","      <td>1.000000</td>\n","      <td>1.668425</td>\n","      <td>-399.507904</td>\n","      <td>-492.236572</td>\n","      <td>-2.071641</td>\n","      <td>-2.216103</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.154900</td>\n","      <td>0.562264</td>\n","      <td>-1.256566</td>\n","      <td>1.000000</td>\n","      <td>1.818829</td>\n","      <td>-299.554504</td>\n","      <td>-412.766357</td>\n","      <td>-2.082393</td>\n","      <td>-2.238643</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.144300</td>\n","      <td>0.564272</td>\n","      <td>-1.319579</td>\n","      <td>1.000000</td>\n","      <td>1.883851</td>\n","      <td>-336.527466</td>\n","      <td>-467.035889</td>\n","      <td>-2.036092</td>\n","      <td>-2.185592</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.106800</td>\n","      <td>0.679793</td>\n","      <td>-1.531843</td>\n","      <td>1.000000</td>\n","      <td>2.211636</td>\n","      <td>-297.239532</td>\n","      <td>-522.380981</td>\n","      <td>-2.074401</td>\n","      <td>-2.162575</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.077900</td>\n","      <td>0.780111</td>\n","      <td>-1.806493</td>\n","      <td>1.000000</td>\n","      <td>2.586604</td>\n","      <td>-430.290558</td>\n","      <td>-572.850830</td>\n","      <td>-2.063411</td>\n","      <td>-2.227042</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.100700</td>\n","      <td>0.846537</td>\n","      <td>-1.551615</td>\n","      <td>1.000000</td>\n","      <td>2.398152</td>\n","      <td>-361.344849</td>\n","      <td>-448.376038</td>\n","      <td>-2.079797</td>\n","      <td>-2.217337</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.061200</td>\n","      <td>0.941401</td>\n","      <td>-1.881302</td>\n","      <td>1.000000</td>\n","      <td>2.822702</td>\n","      <td>-328.022736</td>\n","      <td>-492.529663</td>\n","      <td>-1.984825</td>\n","      <td>-2.226601</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.068200</td>\n","      <td>1.011866</td>\n","      <td>-1.707107</td>\n","      <td>1.000000</td>\n","      <td>2.718973</td>\n","      <td>-419.878510</td>\n","      <td>-434.264984</td>\n","      <td>-2.040527</td>\n","      <td>-2.216584</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.053300</td>\n","      <td>0.867305</td>\n","      <td>-2.093352</td>\n","      <td>1.000000</td>\n","      <td>2.960657</td>\n","      <td>-396.124725</td>\n","      <td>-452.023438</td>\n","      <td>-2.101680</td>\n","      <td>-2.252159</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.017400</td>\n","      <td>0.965059</td>\n","      <td>-1.718367</td>\n","      <td>1.000000</td>\n","      <td>2.683426</td>\n","      <td>-542.232422</td>\n","      <td>-385.312744</td>\n","      <td>-2.025156</td>\n","      <td>-2.127636</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.036400</td>\n","      <td>1.126800</td>\n","      <td>-2.212449</td>\n","      <td>1.000000</td>\n","      <td>3.339248</td>\n","      <td>-477.175415</td>\n","      <td>-481.398865</td>\n","      <td>-2.089967</td>\n","      <td>-2.215419</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.046600</td>\n","      <td>0.885244</td>\n","      <td>-2.271931</td>\n","      <td>1.000000</td>\n","      <td>3.157175</td>\n","      <td>-392.631042</td>\n","      <td>-444.458527</td>\n","      <td>-2.049927</td>\n","      <td>-2.194420</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.035200</td>\n","      <td>1.169140</td>\n","      <td>-2.219623</td>\n","      <td>1.000000</td>\n","      <td>3.388763</td>\n","      <td>-358.936829</td>\n","      <td>-406.734467</td>\n","      <td>-2.029567</td>\n","      <td>-2.147476</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.026900</td>\n","      <td>1.084149</td>\n","      <td>-2.637915</td>\n","      <td>1.000000</td>\n","      <td>3.722063</td>\n","      <td>-312.954803</td>\n","      <td>-483.525604</td>\n","      <td>-2.039297</td>\n","      <td>-2.234631</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.028400</td>\n","      <td>1.233262</td>\n","      <td>-2.591772</td>\n","      <td>1.000000</td>\n","      <td>3.825034</td>\n","      <td>-348.493195</td>\n","      <td>-473.969055</td>\n","      <td>-2.062527</td>\n","      <td>-2.199947</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.022900</td>\n","      <td>1.187308</td>\n","      <td>-2.687829</td>\n","      <td>1.000000</td>\n","      <td>3.875137</td>\n","      <td>-374.434387</td>\n","      <td>-557.982300</td>\n","      <td>-2.050277</td>\n","      <td>-2.208635</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.021400</td>\n","      <td>1.398115</td>\n","      <td>-2.525997</td>\n","      <td>1.000000</td>\n","      <td>3.924112</td>\n","      <td>-312.413513</td>\n","      <td>-446.217499</td>\n","      <td>-1.989372</td>\n","      <td>-2.279169</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.017900</td>\n","      <td>1.395043</td>\n","      <td>-2.692438</td>\n","      <td>1.000000</td>\n","      <td>4.087481</td>\n","      <td>-357.207886</td>\n","      <td>-481.767761</td>\n","      <td>-2.040834</td>\n","      <td>-2.215636</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.020500</td>\n","      <td>1.209734</td>\n","      <td>-2.821622</td>\n","      <td>1.000000</td>\n","      <td>4.031356</td>\n","      <td>-422.244019</td>\n","      <td>-537.424438</td>\n","      <td>-2.095858</td>\n","      <td>-2.233304</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","      <td>No Log</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=33, training_loss=0.24401054689378449, metrics={'train_runtime': 119.7015, 'train_samples_per_second': 2.256, 'train_steps_per_second': 0.276, 'total_flos': 0.0, 'train_loss': 0.24401054689378449, 'epoch': 2.8})"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["metrics = dpo_trainer.evaluate()\n","print(metrics)"],"metadata":{"id":"e6GNBTGDrCMf","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1739209876647,"user_tz":360,"elapsed":4271,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"fc454d37-2e78-4787-9d7c-e9f44c9a0918"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.03484562784433365, 'eval_runtime': 4.26, 'eval_samples_per_second': 5.399, 'eval_steps_per_second': 0.704, 'eval_rewards/chosen': 1.0909239053726196, 'eval_rewards/rejected': -2.4536514282226562, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 3.5445749759674072, 'eval_logps/chosen': -281.712646484375, 'eval_logps/rejected': -502.7544860839844, 'eval_logits/chosen': -2.0394606590270996, 'eval_logits/rejected': -2.183208703994751, 'epoch': 2.8}\n"]}]},{"cell_type":"code","source":["dpo_trainer.save_model('deepseek-r1-reasoning-dpo')"],"metadata":{"id":"t2bCoqU4rD31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.finish()"],"metadata":{"id":"j-K351DZrIJJ","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1739209889256,"user_tz":360,"elapsed":3122,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"72c3b2f3-f8bc-4778-e4b6-df060aa36127"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">generous-vortex-13</strong> at: <a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/zlh19ii8?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/zlh19ii8?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01</a><br> View project at: <a href='https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough?apiKey=74e1599fd25989e53e27f4d82a7447f0c0aecb01</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250210_164727-zlh19ii8/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Model use"],"metadata":{"id":"KzeqfeG7rIp5"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","# Path to your fine-tuned model\n","model_path = \"drive/MyDrive/deepseek-r1-reasoning-dpo\"  # Replace\n","tokenizer_path = \"drive/MyDrive/tokenizer-deepseek-r1-with-reasoning-0.01\"\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n","\n","# Load the base model optimized with Unsloth\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=model_path,\n","    max_seq_length=4096,  # Adjust based on model capability\n","    dtype=torch.float16,\n","    load_in_4bit=True,  # Enable quantization for efficiency\n",")\n"],"metadata":{"id":"P7zNZFPYrJ_h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739210265342,"user_tz":360,"elapsed":15648,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"b559a3cd-4a5f-455c-c5f6-c08fc32727a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["# Optimize LoRA model for inference (2x faster with Unsloth)\n","FastLanguageModel.for_inference(model)\n","\n","# Move model to GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"id":"tq7JRt83rW8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739210269690,"user_tz":360,"elapsed":22,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"b8af4f1a-cbcb-4523-fb73-367180a4c61c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["# Define a system prompt under prompt_style\n","prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n","Write a response that appropriately completes the request.\n","Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n","\n","### Instruction:\n","You are a customer service representative with advanced knowledge of water filtration systems, troubleshooting, and warranty replacements. Please answer the following customer inquiry professionally and helpfully.\n","\n","### Question:\n","{}\n","\n","### Response:\n","<think>{}\"\"\""],"metadata":{"id":"XOlMnH0krZEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the input question and prompt format\n","question = '''Product Name: WSP50ARB | I am looking for a sediment filter to catch the sediment leaving my tankless water heater. Will this filter withstand the 120 degree setting?\n","Sent from my iPhone\n","'''\n","\n","\n","# Tokenize input\n","inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(device)\n","\n","# Generate response\n","outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=2048)\n","\n","# Decode output\n","response = tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[1].strip()\n","\n","print(\"Model's Response:\", response)"],"metadata":{"id":"F5hPLFFZra19","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739210310913,"user_tz":360,"elapsed":37400,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"301cabc3-07ba-41ef-b25b-64c0da02f2b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model's Response: <think>\n","Okay, so I need to help this customer who's asking about the WSP50ARB sediment filter for their tankless water heater. They want to know if it can handle the 120-degree setting. First, I should recall what I know about tankless water heaters and their filtration systems. \n","\n","I remember that tankless systems often have built-in filters, usually sediment filters, to protect the heat exchanger from particles that could clog it or cause damage. The WSP50ARB is a specific model, so I should check the specs for that exact filter. \n","\n","I think the sediment filter's main job is to catch particles as small as 5 microns, which prevents debris from getting into the heater. But the question is about whether it can withstand the high temperature, specifically the 120-degree setting. I should consider the material the filter is made of. If it's made of materials that can handle high temps without degrading, like maybe something heat-resistant, then it should be fine. \n","\n","I also need to think about whether the filter is designed for the specific temperature range of the water heater. Some filters might be rated for lower temps, so using one that's not rated for 120 might not be safe. \n","\n","I should check the maximum temperature rating of the WSP50ARB filter. If it's rated for higher than 120 degrees, that's good. If not, maybe it needs to be replaced with a filter that can handle higher temps. \n","\n","Another point is the flow rate. The filter's efficiency can depend on how quickly water passes through it. If the flow rate is too high, it might not trap all the sediment effectively. So, ensuring the filter is rated for the correct flow rate is important too. \n","\n","I should also mention that if the customer isn't sure, they might need to consult the manufacturer or check the filter's specifications. Maybe they can look up the WSP50ARB manual or contact the manufacturer directly for the exact temperature and flow rate specs. \n","\n","Additionally, it's good to remind them about regular maintenance, like cleaning or replacing the filter as recommended by the manufacturer, to prevent buildup and ensure optimal performance. \n","\n","Putting it all together, I should structure the response to address each of these points clearly and concisely, making sure it's helpful and professional.\n","</think>\n","\n","The WSP50ARB sediment filter is designed to handle temperatures up to 120 degrees, making it suitable for your tankless water heater. It effectively traps particles as small as 5 microns, preventing debris from entering the system. The filter's material is heat-resistant, ensuring it performs well at the required temperature. Additionally, it is rated for the appropriate flow rate, ensuring efficient sediment trapping. For the best performance, it's recommended to follow the manufacturer's maintenance guidelines, which may include regular cleaning or filter replacement. If you need more specific information, consulting the manufacturer's manual or contacting their support team is advisable.<｜end▁of▁sentence｜>\n"]}]},{"cell_type":"code","source":["def use_model(model, tokenizer, prompt_style, question):\n","\n","  # Load the base model optimized with Unsloth\n","  model, tokenizer = FastLanguageModel.from_pretrained(\n","      model_name=model_path,\n","      max_seq_length=4096,  # Adjust based on model capability\n","      dtype=torch.float16,\n","      load_in_4bit=True,  # Enable quantization for efficiency\n","  )\n","\n","  # Optimize LoRA model for inference (2x faster with Unsloth)\n","  FastLanguageModel.for_inference(model)\n","\n","  # Move model to GPU if available\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  model.to(device)\n","\n","  print(\"Model loaded successfully!\")\n","\n","  # Tokenize input\n","  inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(device)\n","\n","  # Generate response\n","  outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=2048)\n","\n","  # Decode output\n","  response = tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[1].strip()\n","\n","  print(\"Model's Response:\", response)"],"metadata":{"id":"1XvMv_YCVTy3"},"execution_count":null,"outputs":[]}]}