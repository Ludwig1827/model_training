{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1738254341226,"user_tz":360,"elapsed":127726,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[],"source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","\n","# We have to check which Torch version for Xformers (2.3 -> 0.0.27)\n","from torch import __version__; from packaging.version import Version as V\n","xformers = \"xformers==0.0.27\" if V(__version__) < V(\"2.4.0\") else \"xformers\"\n","!pip install --no-deps {xformers} trl peft accelerate bitsandbytes triton"]},{"cell_type":"markdown","metadata":{"id":"r2v_X2fA0Df5"},"source":["* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316,"referenced_widgets":["7adb9231dd7445a484a8c31ba1b4d3fb","fa455e6eb99a402b83758a645975335a","c19515a9f29c4f63b8dd4105dbb0839a","3becf2ddf1fd4af09517959fc239606f","712ee3b524b647e489e2b08dbb13a399","fe00a95799634bf59be39b79b8bf5f7e","a6440a794c4d47cb9aee51da6fbd23cd","e8f96c5015464abe9412ed7f4762da32","56d7ac1f0d8e48f98b002da1b8cbcfda","924dc192ed2b4da5a17213d3169553b4","aed01d30e2414de6b3de9603dd4da05c","0c370853b2ed4a0196b88ecf2ec51702","f0c1f091d08647e29bb5b1e900f14802","2d701c94c71b4aeba2be0e9ef42276de","3982a0df5f684a67a89db1260763ce03","b302f0b806d649e98a8ac6219b941e1d","f3298b098d5b42c7ba9586cd3c3997a4","a6b1336e669d4dd08c0e30d552fe2436","82d53396368a442fa9d258eafd180adf","7318ba3504db465bb5884120511a9468","9a0ca85974bf46d5803a7655bbb78026","632c5811c5a84379a076333a381dc859","55d68e5d48134d6cbd7e527a2633e1a9","e0cb5710ba9f4ac9ab08404274f3f7e7","f4cabc02d4a9456993ea125692038a5e","2594ae87679e40f7891c30a0f7c5956d","7aaed91be8e242ba9cb6f673a1121b2b","3972bf3db5a642b4917c19e2a312d2fa","e098b69c97ae4c9286a85659a0ec3765","7d9ade02fdbd43209f4288c090002966","bbcd48f7cc9840d9829dec04af9846ac","760d78c33a2043deaf3299aad9eb2bd8","6e7d1c8bea964d95a72cac915d216433","a7b95eea56d842028d84ad63c7343799","1c9cb711fbab4e09987e48c84765f811","9e8b7e3f1a184c57adaab9c0c37e7396","810635c0bba8427ea8237919d2850c17","e6a6142fbd244222893a4a9daf6bd6c1","8895b54f028e48f59d739e6aba2c6568","dce698225fb64fcaaa3a69148f18778d","159ba50dad6249f9b6ec73f9454098f0","28ffc86483f94e5d956617493fb7bf98","e83d25620b3c4c27a371d8ae47d67589","b65ca73c1afd4c37909009ccccec02b3","f0d98e0e59504fdb943d47017123d172","c0d385f9ad9b47a8b8943c818bbf9750","e42f2b7c118c48a99614e4cf3236cfc2","4da5da1ed21849a08e0fbbcc59372c1e","7eb4a00159ae4454882c56e12fb6c4d4","8f17142550fa4e02a9df059dbd46e5e1","93ddfb2a4b604b08b25289d21c9c013e","2ce3d57bb6d742f297fa83bfca27ee76","75c323cf92934ede9ac40b693ef87d35","1930d4032d1f422ca53caaac31b11d65","5b77991ff43541b3936ee15a4fbad508"]},"executionInfo":{"elapsed":39697,"status":"ok","timestamp":1738249675396,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"},"user_tz":360},"id":"QmUBVEnvCDJv","outputId":"1e6e6f0e-f962-4049-95b9-6b840d898b7e"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Ε Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Ε Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.1.7: Fast Llama patching. Transformers: 4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7adb9231dd7445a484a8c31ba1b4d3fb","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c370853b2ed4a0196b88ecf2ec51702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55d68e5d48134d6cbd7e527a2633e1a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b95eea56d842028d84ad63c7343799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d98e0e59504fdb943d47017123d172"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    # \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    # \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    # \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    # \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    # \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    # \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    # \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    # \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n","    # \"unsloth/Phi-3-medium-4k-instruct\",\n","    # \"unsloth/gemma-2-9b-bnb-4bit\",\n","    # \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","    # \"unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF\",\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10786,"status":"ok","timestamp":1738164154336,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"},"user_tz":360},"id":"6bZsfBuZDeCL","outputId":"6f252fb8-b28f-40d1-b1db-04195fc4ef1f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.1.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n","\n","If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","# Load the dataset\n","file_path = 'faq.csv'  # Replace with your file path\n","df = pd.read_csv(file_path, encoding='utf-8')\n","\n","# 1. Remove Irrelevant Data\n","# Ensure only the necessary columns are present\n","df = df[['Product_Model', 'Product_Name', 'Customer_Question', 'Answer']]\n","\n","# 2. Check for Missing Data\n","# Remove rows with any missing values\n","df.dropna(inplace=True)\n","\n","# 3. Normalize Text\n","def normalize_text(text):\n","    # Convert to lowercase \\u200e \\u201d\n","    text = text.lower()\n","    #text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Removes non-ASCII characters\n","    # Remove specific unwanted Unicode sequences\n","    text = re.sub(r'\\u200e', '', text)\n","    text = re.sub(r'\\u201d', '', text)\n","    text = re.sub(r'\\\\u2019', '', text)\n","    # Remove punctuation\n","    #text = re.sub(r'[^\\w\\s]', '', text)\n","    # Expand contractions (e.g., can't -> cannot)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"'re\", \" are\", text)\n","    text = re.sub(r\"'s\", \" is\", text)\n","    text = re.sub(r\"'d\", \" would\", text)\n","    text = re.sub(r\"'ll\", \" will\", text)\n","    text = re.sub(r\"'t\", \" not\", text)\n","    text = re.sub(r\"'ve\", \" have\", text)\n","    text = re.sub(r\"'m\", \" am\", text)\n","    text = re.sub(r\"123filter.com\", \"ispringfilter.com\", text)\n","    return text\n","\n","# Apply normalization to the relevant columns\n","df['Product_Model'] = df['Product_Model'].apply(normalize_text)\n","df['Customer_Question'] = df['Customer_Question'].apply(normalize_text)\n","df['Answer'] = df['Answer'].apply(normalize_text)\n","\n","\n","# 4. Deduplicate\n","# Remove duplicate rows\n","df.drop_duplicates(inplace=True)\n","\n","# 5. Format Data for Fine-Tuning\n","def format_for_finetuning(row):\n","    prompt = f\"{row['Product_Model']} - customer: {row['Customer_Question']} support:\"\n","    completion = f\" {row['Answer']}\"\n","    return {'prompt': prompt, 'completion': completion}\n","\n","# Apply formatting to the entire dataframe\n","formatted_data = df.apply(format_for_finetuning, axis=1)\n","\n","# Convert to a list of dictionaries (one dictionary per row)\n","formatted_data = formatted_data.to_list()\n","\n","# Save the formatted data to a JSONL file\n","import json\n","\n","output_file_path = 'formatted_conversations.jsonl'  # Specify your output path\n","with open(output_file_path, 'w') as outfile:\n","    for entry in formatted_data:\n","        json.dump(entry, outfile)\n","        outfile.write('\\n')\n","\n","print(\"Data cleanup and formatting completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRHwfZ2ciRlN","executionInfo":{"status":"ok","timestamp":1738164200941,"user_tz":360,"elapsed":721,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"c93e2e98-895b-47a4-8610-6b8ac4d80da3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data cleanup and formatting completed successfully!\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"Vdr9x14jrNjH","executionInfo":{"status":"ok","timestamp":1738164209559,"user_tz":360,"elapsed":580,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"eeb3566a-e35b-4bc9-83cc-4018183df4a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Product_Model                                       Product_Name  \\\n","0          rcc7ak  iSpring RCC7AK, NSF Certified 75 GPD, 6-Stage ...   \n","1           rcc7p  iSpring RCC7P 75 GPD Reverse Osmosis System wi...   \n","2           rcc7p  iSpring RCC7P 75 GPD Reverse Osmosis System wi...   \n","3           rcc7p  iSpring RCC7P 75 GPD Reverse Osmosis System wi...   \n","4           rcc7p  iSpring RCC7P 75 GPD Reverse Osmosis System wi...   \n","..            ...                                                ...   \n","614      wsp50arj  iSpring WSP50ARJ Spin-Down Sediment Water Filt...   \n","615      wsp50arj  iSpring WSP50ARJ Spin-Down Sediment Water Filt...   \n","616      wsp50arj  iSpring WSP50ARJ Spin-Down Sediment Water Filt...   \n","617      wsp50arj  iSpring WSP50ARJ Spin-Down Sediment Water Filt...   \n","618      wsp50arj  iSpring WSP50ARJ Spin-Down Sediment Water Filt...   \n","\n","                                     Customer_Question  \\\n","0    will this filter salt water and make it drinka...   \n","1    what was the difference between a permeate and...   \n","2    good afternoon, what is the minimum pressure w...   \n","3       can i hook up this system with multiple tanks?   \n","4    can i hook up this system to the ice maker on ...   \n","..                                                 ...   \n","614  is this a stand alone unit or is other equipme...   \n","615  my drain is far away from the filter. how do y...   \n","616                           will this prevent scale?   \n","617  i replace a 1 micron 10x2 cartridge every 3-4 ...   \n","618                 is it ok to backflush this filter?   \n","\n","                                                Answer  \n","0    no, this system is not designed to filter salt...  \n","1    i have a water softener + this ro system for 4...  \n","2    thank you for your question! the pump needs ab...  \n","3    dear customer,\\thanks for the inquiry! yes you...  \n","4    yes you sure can. we actually are offering a i...  \n","..                                                 ...  \n","614  the whole house sediment filter uses a 100-mic...  \n","615  this needs to be installed into a drain line. ...  \n","616  the whole house sediment filter uses a 100-mic...  \n","617  the whole house sediment filter uses a 50-micr...  \n","618  the whole house spin-down sediment water filte...  \n","\n","[601 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-c3b1e376-18cb-49c9-8d66-b5c65c12800f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product_Model</th>\n","      <th>Product_Name</th>\n","      <th>Customer_Question</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>rcc7ak</td>\n","      <td>iSpring RCC7AK, NSF Certified 75 GPD, 6-Stage ...</td>\n","      <td>will this filter salt water and make it drinka...</td>\n","      <td>no, this system is not designed to filter salt...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>rcc7p</td>\n","      <td>iSpring RCC7P 75 GPD Reverse Osmosis System wi...</td>\n","      <td>what was the difference between a permeate and...</td>\n","      <td>i have a water softener + this ro system for 4...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>rcc7p</td>\n","      <td>iSpring RCC7P 75 GPD Reverse Osmosis System wi...</td>\n","      <td>good afternoon, what is the minimum pressure w...</td>\n","      <td>thank you for your question! the pump needs ab...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rcc7p</td>\n","      <td>iSpring RCC7P 75 GPD Reverse Osmosis System wi...</td>\n","      <td>can i hook up this system with multiple tanks?</td>\n","      <td>dear customer,\\thanks for the inquiry! yes you...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>rcc7p</td>\n","      <td>iSpring RCC7P 75 GPD Reverse Osmosis System wi...</td>\n","      <td>can i hook up this system to the ice maker on ...</td>\n","      <td>yes you sure can. we actually are offering a i...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>wsp50arj</td>\n","      <td>iSpring WSP50ARJ Spin-Down Sediment Water Filt...</td>\n","      <td>is this a stand alone unit or is other equipme...</td>\n","      <td>the whole house sediment filter uses a 100-mic...</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>wsp50arj</td>\n","      <td>iSpring WSP50ARJ Spin-Down Sediment Water Filt...</td>\n","      <td>my drain is far away from the filter. how do y...</td>\n","      <td>this needs to be installed into a drain line. ...</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>wsp50arj</td>\n","      <td>iSpring WSP50ARJ Spin-Down Sediment Water Filt...</td>\n","      <td>will this prevent scale?</td>\n","      <td>the whole house sediment filter uses a 100-mic...</td>\n","    </tr>\n","    <tr>\n","      <th>617</th>\n","      <td>wsp50arj</td>\n","      <td>iSpring WSP50ARJ Spin-Down Sediment Water Filt...</td>\n","      <td>i replace a 1 micron 10x2 cartridge every 3-4 ...</td>\n","      <td>the whole house sediment filter uses a 50-micr...</td>\n","    </tr>\n","    <tr>\n","      <th>618</th>\n","      <td>wsp50arj</td>\n","      <td>iSpring WSP50ARJ Spin-Down Sediment Water Filt...</td>\n","      <td>is it ok to backflush this filter?</td>\n","      <td>the whole house spin-down sediment water filte...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>601 rows  4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3b1e376-18cb-49c9-8d66-b5c65c12800f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c3b1e376-18cb-49c9-8d66-b5c65c12800f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c3b1e376-18cb-49c9-8d66-b5c65c12800f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a56f448c-5b52-4a9b-8970-4ed30ee8d032\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a56f448c-5b52-4a9b-8970-4ed30ee8d032')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a56f448c-5b52-4a9b-8970-4ed30ee8d032 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_0883b2ac-8619-48d5-90ff-81bf0f0be8e0\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0883b2ac-8619-48d5-90ff-81bf0f0be8e0 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 601,\n  \"fields\": [\n    {\n      \"column\": \"Product_Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"rcc7ak\",\n          \"us31\",\n          \"ro600bn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product_Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 58,\n        \"samples\": [\n          \"iSpring RCC7AK, NSF Certified 75 GPD, 6-Stage Reverse Osmosis System, pH+ Alkaline Remineralization RO Water Filter System Under Sink, Superb Taste Drinking Water Filter\",\n          \"iSpring US31 Classic 3-Stage Under Sink Water Filtration System for Drinking, Tankless, High Capacity, Sediment + Carbon + Carbon (Newest Version)\",\n          \"iSpring RO600ORB Tankless RO Reverse Osmosis Water Filtration System\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer_Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 569,\n        \"samples\": [\n          \"is this made of stainless steel, aluminum, or? will i get dielectric corrosion if i connect it to steel pipe? if i connect to a copper or bronze pip\",\n          \"i installed immune backwards. (water in the out, and out the in) will it still work okay?\",\n          \"there are no instruction manual in the package. how do you install the 5th stage and transfer over the 1/4 quick connector?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 592,\n        \"samples\": [\n          \"hi, if you plan on installing this far away from the points of use, like more than 15 feet, then we recommend installing a demand/delivery pump. we recommend the company aquatec who makes a good demand pump. their model number for the pump we recommend is 5851-7e12-j574. it can be found on amazon. if you have any questions or need additional assistance, please contact us at support@ispringfilter.com or call us at (678) 261-7611.\",\n          \"it is ready to use, we suggest dumping your first tank as part of the set up process. this allows for the post carbon filter to be flushed and will remove any carbon dust.\",\n          \"hi astroidor, yes! this is perfect for any ro system that can connect using a 1/4\\\" or 3/8\\\" ro tubings.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["bec13b7d988646d7bfb41918f06fee14","3420f77f8e324d73ac0a0b8a4092d9c2","8a0737ce80cb41d9a524bb5b3e5a3a8a","def3df1f0bc54e79b85f5cda2ff339d9","1c1cd27a412e49e692207437e82a2d63","39fdb867771e4d24946f714ce89ea103","1ebaa5432c2641b69d1d8d11f7f0522f","9951fd2b4f49425da865af304fe8aaa4","78f6202727a84d90b8eeb20de4e33b40","395fb1e009b041d39f720ae10382f684","5f0a5c6961984f51bcd15d12961d7308","89af8eddf3524f2f82cbe8f76c4f7b1c","201461d31dbd4961b1808a7e2603f62c","9790c6e6ea1446c3b7b9077782eb4535","5244d71707e24d8a8e8ce7fe1ed1dc2b","40682e54b3884d1c94feee22aa978e2e","466f7e6080a14c58bd7f644c5f0b9b95","a5c21521f320420892e3d7067808960d","672a2a6daecb452eb92cb14017671546","8ea71ab80c42482091db5db907d8b7f4","3e6577cc8d6c4597aae8111f6e07458e","3a6df0aad59e45549c7a6f0840b61196","586086ffbe1c4c54bf6f80efa5fd289d","68bc2fe587ab45beb2dd2768315dd997","78a200da11bf49ca908f60cf11d3f0f3","86d3a9605c534de1b3305b63687dda8c","41bc19246a7343fb811b39a528278c64","e1c5cde4560d4143a953d76b5722949a","fb385ceb80cc4b33b4b9777c934effd9","20306e6af2864c7bba7f46f9aa1e6859","6a109000e10c45a28c2e554e9dc5559c","dd4e65c300234b179190d15b82c981fd","34dcab90e10e4ffcb22409c604172eb1","fb50c33361f941878d0a319ce13a9f9b","f61e9f85a99249e8999535a480591f64","8df660136cba4ba89f967376e10b6aa1","3c6cd408582344aea29d4ef276b0a3b8","4010bf5ead1c48a0b97fa769375a4e3c","7f33de04e8aa45dc89e221282f8afc5a","18f82dcf90cc44c6b71996a7a995cc58","c20f34d2b3e84b6796bb767d33736f87","f396d8a6000242f485dc98cad2740cb9","54f2b68bfe05423ead250dd9f115df2a","c9227064b1924edc880eb6ccf70d5cd8"]},"executionInfo":{"elapsed":4968,"status":"ok","timestamp":1738164218038,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"},"user_tz":360},"id":"LjY75GoYUCB8","outputId":"4f36296d-b6ec-454f-f4dc-d979b8b75acb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec13b7d988646d7bfb41918f06fee14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["alpaca_data_cleaned.json:   0%|          | 0.00/44.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89af8eddf3524f2f82cbe8f76c4f7b1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"586086ffbe1c4c54bf6f80efa5fd289d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/51760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb50c33361f941878d0a319ce13a9f9b"}},"metadata":{}}],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d9b60dfd6a804652a3f1aaa42de5555c","8c3443abd4bd41e2992844b8140f064f","3e0485e0c71f400589e3c18eca739b1c","1ff9ca402af643568fd047e7bd94ced3","268bbf2023eb423ba8d76c6c39641076","13b096fa34fb48b19f7348ab7516c691","142af8489c15411db3933fbabd0acc6d","ed8cb8cad5954b189bb9f40aa400c65f","aa61b1e44b564ee38363d6cbcc05f99e","651b50ad70c04e52a6dc34e503093e75","8cfec244f2894ea2b1c93deffa361703"]},"executionInfo":{"elapsed":34620,"status":"ok","timestamp":1738164387105,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"},"user_tz":360},"id":"95_Nn-89DhsL","outputId":"700a8559-6b83-482c-dcef-94ce6c44325a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/51760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b60dfd6a804652a3f1aaa42de5555c"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":541,"status":"ok","timestamp":1738164389137,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"},"user_tz":360},"id":"2ejIt2xSNKKp","outputId":"ceeb5772-c910-4c83-e572-153d138401e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","6.479 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"4bba88bf-d9cb-4c96-92f5-03eb3de7bbf6","executionInfo":{"status":"ok","timestamp":1738164968290,"user_tz":360,"elapsed":578072,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 51,760 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" 路路路路路路路路路路\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250129_152835-oju6et1q</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/beeth-xue-rice-university/huggingface/runs/oju6et1q' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/beeth-xue-rice-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/beeth-xue-rice-university/huggingface' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/beeth-xue-rice-university/huggingface/runs/oju6et1q' target=\"_blank\">https://wandb.ai/beeth-xue-rice-university/huggingface/runs/oju6et1q</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 07:22, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.585600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.983400</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.682000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.841400</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.653100</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.433300</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.032600</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.242600</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.123400</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.090100</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.924100</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.038600</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.915100</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.073600</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.904400</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.870000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.020600</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.364500</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.082000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.883500</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.938300</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.000400</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.025300</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.017100</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.074300</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.043400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.082400</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.971800</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.937900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.808000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.874900</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.882000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.020600</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.907700</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.018600</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.874400</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.831100</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.740600</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.076300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.237600</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.910400</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.983700</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.909800</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.901600</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.979700</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.954300</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.807800</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.268400</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.871000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.105300</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.047800</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.918600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.990000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>1.234500</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.813800</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.027300</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.908500</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.785300</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.866000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.924200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"pCqnaKmlO1U9","outputId":"63f4af2b-c212-4f34-dd05-240506fe280a","executionInfo":{"status":"ok","timestamp":1738164987908,"user_tz":360,"elapsed":175,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["574.256 seconds used for training.\n","9.57 minutes used for training.\n","Peak reserved memory = 7.299 GB.\n","Peak reserved memory for training = 0.82 GB.\n","Peak reserved memory % of max memory = 49.491 %.\n","Peak reserved memory for training % of max memory = 5.56 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"ekOmTR1hSNcr"},"source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3gIAX-SM2q","outputId":"5330875d-46ce-471f-f63e-c45b8042fa20","executionInfo":{"status":"ok","timestamp":1738165002505,"user_tz":360,"elapsed":4746,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025']"]},"metadata":{},"execution_count":16}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"]},{"cell_type":"markdown","metadata":{"id":"CrSvZObor0lY"},"source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2pEuRb1r2Vg","outputId":"c3e96d87-3102-42ff-cd58-0bb4ead113b7","executionInfo":{"status":"ok","timestamp":1738165015551,"user_tz":360,"elapsed":9637,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Continue the fibonnaci sequence.\n","\n","### Input:\n","1, 1, 2, 3, 5, 8\n","\n","### Response:\n","1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5778577, 9275249,\n"]}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"8658667e-da85-4d21-eb50-c6398ec160c7","executionInfo":{"status":"ok","timestamp":1738165026711,"user_tz":360,"elapsed":1304,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":18}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"AEEcJ4qfC7Lp"},"source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKX_XKs_BNZR","outputId":"236d87de-3301-4906-bfd2-bdb5708ad80f","executionInfo":{"status":"ok","timestamp":1738165049615,"user_tz":360,"elapsed":7229,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","What is a famous tall tower in Paris?\n","\n","### Input:\n","\n","\n","### Response:\n","The famous tall tower in Paris is the Eiffel Tower. It stands at a height of 324 meters and is one of the most recognizable landmarks in the world. The Eiffel Tower was built for the 1889 World's Fair and was originally intended to be a temporary structure. However, it has become a permanent part of the Parisian skyline and is now one of the city's most iconic symbols.<|eot_id|>\n"]}],"source":["if False:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","# alpaca_prompt = You MUST copy from above!\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"What is a famous tall tower in Paris?\", # instruction\n","        \"\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"markdown","metadata":{"id":"QQMjaNrjsU5_"},"source":["You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFfaXG0WsQuE"},"outputs":[],"source":["if False:\n","    # I highly do NOT suggest - use Unsloth if possible\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        load_in_4bit = load_in_4bit,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"]},{"cell_type":"code","source":["!curl -fsSL https://ollama.com/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SuiTFgxtnDE","executionInfo":{"status":"ok","timestamp":1738165164449,"user_tz":360,"elapsed":74303,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"24cf8d08-c371-4b32-eb0f-acaaa30775ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> Installing ollama to /usr/local\n",">>> Downloading Linux amd64 bundle\n","############################################################################################# 100.0%\n",">>> Creating ollama user...\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n","\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}]},{"cell_type":"code","source":["# Save to 8bit Q8_0\n","if True: model.save_pretrained_gguf(\"model\", tokenizer,)\n","# Remember to go to https://huggingface.co/settings/tokens for a token!\n","# And change hf to your username!\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n","\n","# Save to multiple GGUF options - much faster if you want multiple!\n","if False:\n","    model.push_to_hub_gguf(\n","        \"hf/model\", # Change hf to your username!\n","        tokenizer,\n","        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n","        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t917AtUVt-mM","executionInfo":{"status":"ok","timestamp":1738165870382,"user_tz":360,"elapsed":665016,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"db0369ab-8a7e-4ced-fb12-a5696fa1be47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 5.7G\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 5.06 out of 12.67 RAM for saving.\n","Unsloth: Saving model... This might take 5 minutes ...\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|     | 15/32 [00:01<00:01, 11.50it/s]\n","We will save to Disk and not RAM now.\n","100%|| 32/32 [01:58<00:00,  3.72s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving model/pytorch_model-00001-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00002-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00003-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00004-of-00004.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting llama model. Can use fast conversion = False.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q8_0'] might take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: Installing llama.cpp. This might take 3 minutes...\n","Unsloth: CMAKE detected. Finalizing some steps for installation.\n","Unsloth: [1] Converting model at model into q8_0 GGUF format.\n","The output location will be /content/model/unsloth.Q8_0.gguf\n","This might take 3 minutes...\n","INFO:hf-to-gguf:Loading model: model\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n","INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> Q8_0, shape = {4096, 128256}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n","INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output.weight,               torch.float16 --> Q8_0, shape = {4096, 128256}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 131072\n","INFO:hf-to-gguf:gguf: embedding length = 4096\n","INFO:hf-to-gguf:gguf: feed forward length = 14336\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 8\n","INFO:hf-to-gguf:gguf: rope theta = 500000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 7\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","2025-01-29 15:47:18.359942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-01-29 15:47:18.389154: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-01-29 15:47:18.396777: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-01-29 15:47:20.796454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","INFO:gguf.vocab:Adding 280147 merge(s).\n","INFO:gguf.vocab:Setting special token type bos to 128000\n","INFO:gguf.vocab:Setting special token type eos to 128009\n","INFO:gguf.vocab:Setting special token type pad to 128004\n","INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n","{%- if custom_tools is defined %}\n","    {%- set tools = custom_tools %}\n","{%- endif %}\n","{%- if not tools_in_user_message is defined %}\n","    {%- set tools_in_user_message = true %}\n","{%- endif %}\n","{%- if not date_string is defined %}\n","    {%- set date_string = \"26 Jul 2024\" %}\n","{%- endif %}\n","{%- if not tools is defined %}\n","    {%- set tools = none %}\n","{%- endif %}\n","\n","{#- This block extracts the system message, so we can slot it into the right place. #}\n","{%- if messages[0]['role'] == 'system' %}\n","    {%- set system_message = messages[0]['content']|trim %}\n","    {%- set messages = messages[1:] %}\n","{%- else %}\n","    {%- set system_message = \"\" %}\n","{%- endif %}\n","\n","{#- System message + builtin tools #}\n","{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n","{%- if builtin_tools is defined or tools is not none %}\n","    {{- \"Environment: ipython\\n\" }}\n","{%- endif %}\n","{%- if builtin_tools is defined %}\n","    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n","{%- endif %}\n","{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n","{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n","{%- if tools is not none and not tools_in_user_message %}\n","    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","{%- endif %}\n","{{- system_message }}\n","{{- \"<|eot_id|>\" }}\n","\n","{#- Custom tools are passed in a user message with some extra guidance #}\n","{%- if tools_in_user_message and not tools is none %}\n","    {#- Extract the first user message so we can plug it in here #}\n","    {%- if messages | length != 0 %}\n","        {%- set first_user_message = messages[0]['content']|trim %}\n","        {%- set messages = messages[1:] %}\n","    {%- else %}\n","        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n","{%- endif %}\n","    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n","    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n","    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","    {{- first_user_message + \"<|eot_id|>\"}}\n","{%- endif %}\n","\n","{%- for message in messages %}\n","    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n","        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n","    {%- elif 'tool_calls' in message %}\n","        {%- if not message.tool_calls|length == 1 %}\n","            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n","        {%- endif %}\n","        {%- set tool_call = message.tool_calls[0].function %}\n","        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n","            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n","            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n","            {%- for arg_name, arg_val in tool_call.arguments | items %}\n","                {{- arg_name + '=\"' + arg_val + '\"' }}\n","                {%- if not loop.last %}\n","                    {{- \", \" }}\n","                {%- endif %}\n","                {%- endfor %}\n","            {{- \")\" }}\n","        {%- else  %}\n","            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n","            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n","            {{- '\"parameters\": ' }}\n","            {{- tool_call.arguments | tojson }}\n","            {{- \"}\" }}\n","        {%- endif %}\n","        {%- if builtin_tools is defined %}\n","            {#- This means we're in ipython mode #}\n","            {{- \"<|eom_id|>\" }}\n","        {%- else %}\n","            {{- \"<|eot_id|>\" }}\n","        {%- endif %}\n","    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n","        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n","        {%- if message.content is mapping or message.content is iterable %}\n","            {{- message.content | tojson }}\n","        {%- else %}\n","            {{- message.content }}\n","        {%- endif %}\n","        {{- \"<|eot_id|>\" }}\n","    {%- endif %}\n","{%- endfor %}\n","{%- if add_generation_prompt %}\n","    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n","{%- endif %}\n","\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:/content/model/unsloth.Q8_0.gguf: n_tensors = 292, total_size = 8.5G\n","Writing: 100%|| 8.53G/8.53G [03:41<00:00, 38.6Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to /content/model/unsloth.Q8_0.gguf\n","Unsloth: Conversion completed! Output location: /content/model/unsloth.Q8_0.gguf\n"]}]},{"cell_type":"code","source":["import subprocess\n","subprocess.Popen([\"ollama\", \"serve\"])\n","import time\n","time.sleep(3) # Wait for a few seconds for Ollama to load!"],"metadata":{"id":"zzwxAyNFuPGU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f422JgM9sdVT"},"source":["### Saving to float16 for VLLM\n","\n","We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHjt_SMYsd3P"},"outputs":[],"source":["# Merge to 16bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n","\n","# Merge to 4bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n","\n","# Just LoRA adapters\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n","\n","[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqfebeAdT073"},"outputs":[],"source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","# Remember to go to https://huggingface.co/settings/tokens for a token!\n","# And change hf to your username!\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n","\n","# Save to multiple GGUF options - much faster if you want multiple!\n","if False:\n","    model.push_to_hub_gguf(\n","        \"hf/model\", # Change hf to your username!\n","        tokenizer,\n","        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n","        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n","    )"]},{"cell_type":"markdown","metadata":{"id":"bDp0zNpwe6U_"},"source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"markdown","metadata":{"id":"Zt9CHJqO6p30"},"source":["And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n","\n","Some other links:\n","1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n","2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n","3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n","4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n","5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n","6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with  HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n","7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n","8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n","9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n","10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n","\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"]},{"cell_type":"markdown","source":["## Rewarding Model"],"metadata":{"id":"BDCj-mRJ3j4O"}},{"cell_type":"code","source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Optional set GPU device ID\n","\n","from unsloth import FastLanguageModel, PatchDPOTrainer\n","from unsloth import is_bfloat16_supported\n","PatchDPOTrainer()\n","import torch\n","from transformers import TrainingArguments\n","from trl import DPOTrainer\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/zephyr-sft-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = None,\n","    load_in_4bit = True,\n",")\n","\n","# Do model patching and add fast LoRA weights\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 64,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 64,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    max_seq_length = max_seq_length,\n",")\n","\n","dpo_trainer = DPOTrainer(\n","    model = model,\n","    ref_model = None,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 4,\n","        gradient_accumulation_steps = 8,\n","        warmup_ratio = 0.1,\n","        num_train_epochs = 3,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        seed = 42,\n","        output_dir = \"outputs\",\n","    ),\n","    beta = 0.1,\n","    train_dataset = YOUR_DATASET_HERE,\n","    # eval_dataset = YOUR_DATASET_HERE,\n","    tokenizer = tokenizer,\n","    max_length = 1024,\n","    max_prompt_length = 512,\n",")\n","dpo_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"AeNEzHsR3jdq","executionInfo":{"status":"error","timestamp":1738100769517,"user_tz":360,"elapsed":153983,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"63b4e528-b713-4ea9-b3f4-7eaf0dc3bd16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.1.7: Fast Mistral patching. Transformers: 4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'YOUR_DATASET_HERE' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e90b3e236ad6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     ),\n\u001b[1;32m     48\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOUR_DATASET_HERE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# eval_dataset = YOUR_DATASET_HERE,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'YOUR_DATASET_HERE' is not defined"]}]},{"cell_type":"code","source":["!pip install llama-cpp-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2NtanHP9J4X","executionInfo":{"status":"ok","timestamp":1738102233409,"user_tz":360,"elapsed":172498,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"5080a208-e7dd-42fc-b8b3-89f9e44038f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.3.6.tar.gz (66.9 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m66.9/66.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.12.2)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (1.26.4)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.6-cp311-cp311-linux_x86_64.whl size=4070563 sha256=2a412acce05f781a8a555f7ea66473a32a74ab3a08371cdf499b05a27af231f6\n","  Stored in directory: /root/.cache/pip/wheels/e8/96/d2/acfb576f7a58ef0580e2fec8096e5eefd17cc356017089337b\n","Successfully built llama-cpp-python\n","Installing collected packages: diskcache, llama-cpp-python\n","Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.6\n"]}]},{"cell_type":"code","source":["from llama_cpp import Llama\n","\n","llm = Llama.from_pretrained(\n","\trepo_id=\"unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF\",\n","\tfilename=\"DeepSeek-R1-Distill-Llama-8B-F16.gguf\",\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08IOAhfk9In8","executionInfo":{"status":"ok","timestamp":1738103087439,"user_tz":360,"elapsed":362808,"user":{"displayName":"Yutong Xue","userId":"07246430289294807665"}},"outputId":"d07fe4db-fbeb-43c5-f144-61f2ef8b2807"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_model_loader: loaded meta data with 32 key-value pairs and 292 tensors from /root/.cache/huggingface/hub/models--unsloth--DeepSeek-R1-Distill-Llama-8B-GGUF/snapshots/70661aa9b9e6c69734b394916ddbc540fd4731bf/./DeepSeek-R1-Distill-Llama-8B-F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = DeepSeek R1 Distill Llama 8B\n","llama_model_loader: - kv   3:                       general.organization str              = Deepseek Ai\n","llama_model_loader: - kv   4:                           general.basename str              = DeepSeek-R1-Distill-Llama\n","llama_model_loader: - kv   5:                         general.size_label str              = 8B\n","llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   7:                       llama.context_length u32              = 131072\n","llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 14336\n","llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv  11:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 500000.000000\n","llama_model_loader: - kv  13:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  14:                 llama.attention.key_length u32              = 128\n","llama_model_loader: - kv  15:               llama.attention.value_length u32              = 128\n","llama_model_loader: - kv  16:                          general.file_type u32              = 1\n","llama_model_loader: - kv  17:                           llama.vocab_size u32              = 128256\n","llama_model_loader: - kv  18:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n","llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\" \", \" \", \" \", \"...\n","llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n","llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128001\n","llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 128004\n","llama_model_loader: - kv  27:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  28:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n","llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n","llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   66 tensors\n","llama_model_loader: - type  f16:  226 tensors\n","llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n","llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n","llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n","llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n","llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n","llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n","llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n","llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n","llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n","llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n","llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n","llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n","llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n","llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n","llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n","llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n","llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n","llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n","llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n","llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n","llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n","llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n","llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n","llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n","llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n","llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n","llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n","llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n","llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n","llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n","llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n","llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n","llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n","llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n","llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n","llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n","llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n","llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n","llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n","llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n","llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n","llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n","llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n","llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n","llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n","llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n","llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n","llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n","llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n","llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n","llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n","llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n","llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n","llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n","llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n","llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n","llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n","llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n","llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n","llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n","llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n","llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n","llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n","llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n","llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n","llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n","llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n","llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n","llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n","llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n","llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n","llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n","llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n","llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n","llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n","llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n","llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n","llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n","llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n","llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n","llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n","llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n","llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n","llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n","llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n","llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n","llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n","llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n","llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n","llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n","llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n","llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n","llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n","llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n","llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n","llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n","llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n","llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n","llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n","llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n","llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n","llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n","llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n","llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n","llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n","llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n","llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n","llm_load_vocab: control token: 128012 '<锝Assistant锝>' is not marked as EOG\n","llm_load_vocab: control token: 128011 '<锝User锝>' is not marked as EOG\n","llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n","llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n","llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n","llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n","llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n","llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n","llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n","llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n","llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n","llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n","llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n","llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n","llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n","llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n","llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n","llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n","llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n","llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n","llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n","llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n","llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n","llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n","llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n","llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n","llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n","llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n","llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n","llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n","llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n","llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n","llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n","llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n","llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n","llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n","llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n","llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n","llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n","llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n","llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n","llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n","llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n","llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n","llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n","llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n","llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n","llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n","llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n","llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n","llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n","llm_load_vocab: control token: 128000 '<锝beginofsentence锝>' is not marked as EOG\n","llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n","llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n","llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n","llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n","llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n","llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n","llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n","llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n","llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n","llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n","llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n","llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n","llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n","llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n","llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n","llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n","llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n","llm_load_vocab: control token: 128001 '<锝endofsentence锝>' is not marked as EOG\n","llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n","llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n","llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n","llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n","llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n","llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n","llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n","llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n","llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n","llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n","llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n","llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n","llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n","llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n","llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n","llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n","llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n","llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n","llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n","llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n","llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n","llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n","llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n","llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n","llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n","llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n","llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n","llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n","llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n","llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n","llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n","llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n","llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n","llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n","llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n","llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n","llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n","llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n","llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n","llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n","llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n","llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n","llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n","llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n","llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n","llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n","llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n","llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n","llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n","llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n","llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n","llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n","llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n","llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n","llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n","llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n","llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n","llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n","llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n","llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n","llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n","llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n","llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n","llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n","llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n","llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n","llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n","llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n","llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n","llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n","llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n","llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n","llm_load_vocab: control token: 128015 '<锝pad锝>' is not marked as EOG\n","llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n","llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n","llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n","llm_load_vocab: special tokens cache size = 256\n","llm_load_vocab: token to piece cache size = 0.7999 MB\n","llm_load_print_meta: format           = GGUF V3 (latest)\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = BPE\n","llm_load_print_meta: n_vocab          = 128256\n","llm_load_print_meta: n_merges         = 280147\n","llm_load_print_meta: vocab_only       = 0\n","llm_load_print_meta: n_ctx_train      = 131072\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 8\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_swa            = 0\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 4\n","llm_load_print_meta: n_embd_k_gqa     = 1024\n","llm_load_print_meta: n_embd_v_gqa     = 1024\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: f_logit_scale    = 0.0e+00\n","llm_load_print_meta: n_ff             = 14336\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: causal attn      = 1\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 500000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_ctx_orig_yarn  = 131072\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: ssm_dt_b_c_rms   = 0\n","llm_load_print_meta: model type       = 8B\n","llm_load_print_meta: model ftype      = F16\n","llm_load_print_meta: model params     = 8.03 B\n","llm_load_print_meta: model size       = 14.96 GiB (16.00 BPW) \n","llm_load_print_meta: general.name     = DeepSeek R1 Distill Llama 8B\n","llm_load_print_meta: BOS token        = 128000 '<锝beginofsentence锝>'\n","llm_load_print_meta: EOS token        = 128001 '<锝endofsentence锝>'\n","llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n","llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n","llm_load_print_meta: PAD token        = 128004 '<|finetune_right_pad_id|>'\n","llm_load_print_meta: LF token         = 128 ''\n","llm_load_print_meta: EOG token        = 128001 '<锝endofsentence锝>'\n","llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n","llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n","llm_load_print_meta: max token length = 256\n","llm_load_tensors: tensor 'token_embd.weight' (f16) (and 322 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n","llm_load_tensors:   CPU_Mapped model buffer size = 15317.02 MiB\n",".........................................................................................\n","llama_new_context_with_model: n_seq_max     = 1\n","llama_new_context_with_model: n_ctx         = 512\n","llama_new_context_with_model: n_ctx_per_seq = 512\n","llama_new_context_with_model: n_batch       = 512\n","llama_new_context_with_model: n_ubatch      = 512\n","llama_new_context_with_model: flash_attn    = 0\n","llama_new_context_with_model: freq_base     = 500000.0\n","llama_new_context_with_model: freq_scale    = 1\n","llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n","llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n","llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n","llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n","llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n","llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n","llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n","llama_new_context_with_model: graph nodes  = 1030\n","llama_new_context_with_model: graph splits = 1\n","CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n","Model metadata: {'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<锝User锝>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<锝Assistant锝><锝toolcallsbegin锝><锝toolcallbegin锝>' + tool['type'] + '<锝toolsep锝>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<锝toolcallend锝>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<锝toolcallbegin锝>' + tool['type'] + '<锝toolsep锝>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<锝toolcallend锝>'}}{{'<锝toolcallsend锝><锝endofsentence锝>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<锝tooloutputsend锝>' + message['content'] + '<锝endofsentence锝>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<锝Assistant锝>' + content + '<锝endofsentence锝>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<锝tooloutputsbegin锝><锝tooloutputbegin锝>' + message['content'] + '<锝tooloutputend锝>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<锝tooloutputbegin锝>' + message['content'] + '<锝tooloutputend锝>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<锝tooloutputsend锝>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<锝Assistant锝>'}}{% endif %}\", 'tokenizer.ggml.add_space_prefix': 'false', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '1', 'llama.attention.value_length': '128', 'llama.attention.key_length': '128', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.padding_token_id': '128004', 'general.basename': 'DeepSeek-R1-Distill-Llama', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'DeepSeek R1 Distill Llama 8B', 'general.organization': 'Deepseek Ai', 'general.type': 'model', 'general.size_label': '8B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n","Available chat formats from metadata: chat_template.default\n","Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<锝User锝>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<锝Assistant锝><锝toolcallsbegin锝><锝toolcallbegin锝>' + tool['type'] + '<锝toolsep锝>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<锝toolcallend锝>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<锝toolcallbegin锝>' + tool['type'] + '<锝toolsep锝>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<锝toolcallend锝>'}}{{'<锝toolcallsend锝><锝endofsentence锝>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<锝tooloutputsend锝>' + message['content'] + '<锝endofsentence锝>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<锝Assistant锝>' + content + '<锝endofsentence锝>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<锝tooloutputsbegin锝><锝tooloutputbegin锝>' + message['content'] + '<锝tooloutputend锝>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<锝tooloutputbegin锝>' + message['content'] + '<锝tooloutputend锝>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<锝tooloutputsend锝>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<锝Assistant锝>'}}{% endif %}\n","Using chat eos_token: <锝endofsentence锝>\n","Using chat bos_token: <锝beginofsentence锝>\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1OhT4p_LKo8VIDsv1qKyNGsPJZypHe52Y","timestamp":1738099795758},{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1724954957381},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bec13b7d988646d7bfb41918f06fee14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3420f77f8e324d73ac0a0b8a4092d9c2","IPY_MODEL_8a0737ce80cb41d9a524bb5b3e5a3a8a","IPY_MODEL_def3df1f0bc54e79b85f5cda2ff339d9"],"layout":"IPY_MODEL_1c1cd27a412e49e692207437e82a2d63"}},"3420f77f8e324d73ac0a0b8a4092d9c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39fdb867771e4d24946f714ce89ea103","placeholder":"","style":"IPY_MODEL_1ebaa5432c2641b69d1d8d11f7f0522f","value":"README.md:100%"}},"8a0737ce80cb41d9a524bb5b3e5a3a8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9951fd2b4f49425da865af304fe8aaa4","max":11610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78f6202727a84d90b8eeb20de4e33b40","value":11610}},"def3df1f0bc54e79b85f5cda2ff339d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_395fb1e009b041d39f720ae10382f684","placeholder":"","style":"IPY_MODEL_5f0a5c6961984f51bcd15d12961d7308","value":"11.6k/11.6k[00:00&lt;00:00,966kB/s]"}},"1c1cd27a412e49e692207437e82a2d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39fdb867771e4d24946f714ce89ea103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ebaa5432c2641b69d1d8d11f7f0522f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9951fd2b4f49425da865af304fe8aaa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f6202727a84d90b8eeb20de4e33b40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"395fb1e009b041d39f720ae10382f684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f0a5c6961984f51bcd15d12961d7308":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89af8eddf3524f2f82cbe8f76c4f7b1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_201461d31dbd4961b1808a7e2603f62c","IPY_MODEL_9790c6e6ea1446c3b7b9077782eb4535","IPY_MODEL_5244d71707e24d8a8e8ce7fe1ed1dc2b"],"layout":"IPY_MODEL_40682e54b3884d1c94feee22aa978e2e"}},"201461d31dbd4961b1808a7e2603f62c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_466f7e6080a14c58bd7f644c5f0b9b95","placeholder":"","style":"IPY_MODEL_a5c21521f320420892e3d7067808960d","value":"alpaca_data_cleaned.json:100%"}},"9790c6e6ea1446c3b7b9077782eb4535":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_672a2a6daecb452eb92cb14017671546","max":44307561,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ea71ab80c42482091db5db907d8b7f4","value":44307561}},"5244d71707e24d8a8e8ce7fe1ed1dc2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e6577cc8d6c4597aae8111f6e07458e","placeholder":"","style":"IPY_MODEL_3a6df0aad59e45549c7a6f0840b61196","value":"44.3M/44.3M[00:00&lt;00:00,159MB/s]"}},"40682e54b3884d1c94feee22aa978e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"466f7e6080a14c58bd7f644c5f0b9b95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c21521f320420892e3d7067808960d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"672a2a6daecb452eb92cb14017671546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ea71ab80c42482091db5db907d8b7f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e6577cc8d6c4597aae8111f6e07458e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a6df0aad59e45549c7a6f0840b61196":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"586086ffbe1c4c54bf6f80efa5fd289d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68bc2fe587ab45beb2dd2768315dd997","IPY_MODEL_78a200da11bf49ca908f60cf11d3f0f3","IPY_MODEL_86d3a9605c534de1b3305b63687dda8c"],"layout":"IPY_MODEL_41bc19246a7343fb811b39a528278c64"}},"68bc2fe587ab45beb2dd2768315dd997":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1c5cde4560d4143a953d76b5722949a","placeholder":"","style":"IPY_MODEL_fb385ceb80cc4b33b4b9777c934effd9","value":"Generatingtrainsplit:100%"}},"78a200da11bf49ca908f60cf11d3f0f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20306e6af2864c7bba7f46f9aa1e6859","max":51760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a109000e10c45a28c2e554e9dc5559c","value":51760}},"86d3a9605c534de1b3305b63687dda8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd4e65c300234b179190d15b82c981fd","placeholder":"","style":"IPY_MODEL_34dcab90e10e4ffcb22409c604172eb1","value":"51760/51760[00:00&lt;00:00,107107.46examples/s]"}},"41bc19246a7343fb811b39a528278c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1c5cde4560d4143a953d76b5722949a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb385ceb80cc4b33b4b9777c934effd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20306e6af2864c7bba7f46f9aa1e6859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a109000e10c45a28c2e554e9dc5559c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd4e65c300234b179190d15b82c981fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34dcab90e10e4ffcb22409c604172eb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb50c33361f941878d0a319ce13a9f9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f61e9f85a99249e8999535a480591f64","IPY_MODEL_8df660136cba4ba89f967376e10b6aa1","IPY_MODEL_3c6cd408582344aea29d4ef276b0a3b8"],"layout":"IPY_MODEL_4010bf5ead1c48a0b97fa769375a4e3c"}},"f61e9f85a99249e8999535a480591f64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f33de04e8aa45dc89e221282f8afc5a","placeholder":"","style":"IPY_MODEL_18f82dcf90cc44c6b71996a7a995cc58","value":"Map:100%"}},"8df660136cba4ba89f967376e10b6aa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c20f34d2b3e84b6796bb767d33736f87","max":51760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f396d8a6000242f485dc98cad2740cb9","value":51760}},"3c6cd408582344aea29d4ef276b0a3b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54f2b68bfe05423ead250dd9f115df2a","placeholder":"","style":"IPY_MODEL_c9227064b1924edc880eb6ccf70d5cd8","value":"51760/51760[00:00&lt;00:00,90521.05examples/s]"}},"4010bf5ead1c48a0b97fa769375a4e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f33de04e8aa45dc89e221282f8afc5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f82dcf90cc44c6b71996a7a995cc58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c20f34d2b3e84b6796bb767d33736f87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f396d8a6000242f485dc98cad2740cb9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54f2b68bfe05423ead250dd9f115df2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9227064b1924edc880eb6ccf70d5cd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9b60dfd6a804652a3f1aaa42de5555c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c3443abd4bd41e2992844b8140f064f","IPY_MODEL_3e0485e0c71f400589e3c18eca739b1c","IPY_MODEL_1ff9ca402af643568fd047e7bd94ced3"],"layout":"IPY_MODEL_268bbf2023eb423ba8d76c6c39641076"}},"8c3443abd4bd41e2992844b8140f064f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13b096fa34fb48b19f7348ab7516c691","placeholder":"","style":"IPY_MODEL_142af8489c15411db3933fbabd0acc6d","value":"Map(num_proc=2):100%"}},"3e0485e0c71f400589e3c18eca739b1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8cb8cad5954b189bb9f40aa400c65f","max":51760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa61b1e44b564ee38363d6cbcc05f99e","value":51760}},"1ff9ca402af643568fd047e7bd94ced3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_651b50ad70c04e52a6dc34e503093e75","placeholder":"","style":"IPY_MODEL_8cfec244f2894ea2b1c93deffa361703","value":"51760/51760[00:34&lt;00:00,1478.85examples/s]"}},"268bbf2023eb423ba8d76c6c39641076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b096fa34fb48b19f7348ab7516c691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142af8489c15411db3933fbabd0acc6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed8cb8cad5954b189bb9f40aa400c65f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa61b1e44b564ee38363d6cbcc05f99e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"651b50ad70c04e52a6dc34e503093e75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfec244f2894ea2b1c93deffa361703":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7adb9231dd7445a484a8c31ba1b4d3fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa455e6eb99a402b83758a645975335a","IPY_MODEL_c19515a9f29c4f63b8dd4105dbb0839a","IPY_MODEL_3becf2ddf1fd4af09517959fc239606f"],"layout":"IPY_MODEL_712ee3b524b647e489e2b08dbb13a399"}},"fa455e6eb99a402b83758a645975335a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe00a95799634bf59be39b79b8bf5f7e","placeholder":"","style":"IPY_MODEL_a6440a794c4d47cb9aee51da6fbd23cd","value":"model.safetensors:100%"}},"c19515a9f29c4f63b8dd4105dbb0839a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f96c5015464abe9412ed7f4762da32","max":5702746383,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56d7ac1f0d8e48f98b002da1b8cbcfda","value":5702745840}},"3becf2ddf1fd4af09517959fc239606f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_924dc192ed2b4da5a17213d3169553b4","placeholder":"","style":"IPY_MODEL_aed01d30e2414de6b3de9603dd4da05c","value":"5.70G/5.70G[01:23&lt;00:00,133MB/s]"}},"712ee3b524b647e489e2b08dbb13a399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe00a95799634bf59be39b79b8bf5f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6440a794c4d47cb9aee51da6fbd23cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8f96c5015464abe9412ed7f4762da32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d7ac1f0d8e48f98b002da1b8cbcfda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"924dc192ed2b4da5a17213d3169553b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aed01d30e2414de6b3de9603dd4da05c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c370853b2ed4a0196b88ecf2ec51702":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0c1f091d08647e29bb5b1e900f14802","IPY_MODEL_2d701c94c71b4aeba2be0e9ef42276de","IPY_MODEL_3982a0df5f684a67a89db1260763ce03"],"layout":"IPY_MODEL_b302f0b806d649e98a8ac6219b941e1d"}},"f0c1f091d08647e29bb5b1e900f14802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3298b098d5b42c7ba9586cd3c3997a4","placeholder":"","style":"IPY_MODEL_a6b1336e669d4dd08c0e30d552fe2436","value":"generation_config.json:100%"}},"2d701c94c71b4aeba2be0e9ef42276de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82d53396368a442fa9d258eafd180adf","max":234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7318ba3504db465bb5884120511a9468","value":234}},"3982a0df5f684a67a89db1260763ce03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a0ca85974bf46d5803a7655bbb78026","placeholder":"","style":"IPY_MODEL_632c5811c5a84379a076333a381dc859","value":"234/234[00:00&lt;00:00,16.9kB/s]"}},"b302f0b806d649e98a8ac6219b941e1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3298b098d5b42c7ba9586cd3c3997a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6b1336e669d4dd08c0e30d552fe2436":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82d53396368a442fa9d258eafd180adf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7318ba3504db465bb5884120511a9468":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a0ca85974bf46d5803a7655bbb78026":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632c5811c5a84379a076333a381dc859":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55d68e5d48134d6cbd7e527a2633e1a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0cb5710ba9f4ac9ab08404274f3f7e7","IPY_MODEL_f4cabc02d4a9456993ea125692038a5e","IPY_MODEL_2594ae87679e40f7891c30a0f7c5956d"],"layout":"IPY_MODEL_7aaed91be8e242ba9cb6f673a1121b2b"}},"e0cb5710ba9f4ac9ab08404274f3f7e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3972bf3db5a642b4917c19e2a312d2fa","placeholder":"","style":"IPY_MODEL_e098b69c97ae4c9286a85659a0ec3765","value":"tokenizer_config.json:100%"}},"f4cabc02d4a9456993ea125692038a5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d9ade02fdbd43209f4288c090002966","max":55421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bbcd48f7cc9840d9829dec04af9846ac","value":55421}},"2594ae87679e40f7891c30a0f7c5956d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_760d78c33a2043deaf3299aad9eb2bd8","placeholder":"","style":"IPY_MODEL_6e7d1c8bea964d95a72cac915d216433","value":"55.4k/55.4k[00:00&lt;00:00,3.52MB/s]"}},"7aaed91be8e242ba9cb6f673a1121b2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3972bf3db5a642b4917c19e2a312d2fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e098b69c97ae4c9286a85659a0ec3765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d9ade02fdbd43209f4288c090002966":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbcd48f7cc9840d9829dec04af9846ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"760d78c33a2043deaf3299aad9eb2bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e7d1c8bea964d95a72cac915d216433":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7b95eea56d842028d84ad63c7343799":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c9cb711fbab4e09987e48c84765f811","IPY_MODEL_9e8b7e3f1a184c57adaab9c0c37e7396","IPY_MODEL_810635c0bba8427ea8237919d2850c17"],"layout":"IPY_MODEL_e6a6142fbd244222893a4a9daf6bd6c1"}},"1c9cb711fbab4e09987e48c84765f811":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8895b54f028e48f59d739e6aba2c6568","placeholder":"","style":"IPY_MODEL_dce698225fb64fcaaa3a69148f18778d","value":"tokenizer.json:100%"}},"9e8b7e3f1a184c57adaab9c0c37e7396":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_159ba50dad6249f9b6ec73f9454098f0","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28ffc86483f94e5d956617493fb7bf98","value":9085657}},"810635c0bba8427ea8237919d2850c17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e83d25620b3c4c27a371d8ae47d67589","placeholder":"","style":"IPY_MODEL_b65ca73c1afd4c37909009ccccec02b3","value":"9.09M/9.09M[00:00&lt;00:00,22.8MB/s]"}},"e6a6142fbd244222893a4a9daf6bd6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8895b54f028e48f59d739e6aba2c6568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce698225fb64fcaaa3a69148f18778d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"159ba50dad6249f9b6ec73f9454098f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ffc86483f94e5d956617493fb7bf98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e83d25620b3c4c27a371d8ae47d67589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65ca73c1afd4c37909009ccccec02b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0d98e0e59504fdb943d47017123d172":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0d385f9ad9b47a8b8943c818bbf9750","IPY_MODEL_e42f2b7c118c48a99614e4cf3236cfc2","IPY_MODEL_4da5da1ed21849a08e0fbbcc59372c1e"],"layout":"IPY_MODEL_7eb4a00159ae4454882c56e12fb6c4d4"}},"c0d385f9ad9b47a8b8943c818bbf9750":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f17142550fa4e02a9df059dbd46e5e1","placeholder":"","style":"IPY_MODEL_93ddfb2a4b604b08b25289d21c9c013e","value":"special_tokens_map.json:100%"}},"e42f2b7c118c48a99614e4cf3236cfc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ce3d57bb6d742f297fa83bfca27ee76","max":340,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75c323cf92934ede9ac40b693ef87d35","value":340}},"4da5da1ed21849a08e0fbbcc59372c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1930d4032d1f422ca53caaac31b11d65","placeholder":"","style":"IPY_MODEL_5b77991ff43541b3936ee15a4fbad508","value":"340/340[00:00&lt;00:00,27.4kB/s]"}},"7eb4a00159ae4454882c56e12fb6c4d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f17142550fa4e02a9df059dbd46e5e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93ddfb2a4b604b08b25289d21c9c013e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ce3d57bb6d742f297fa83bfca27ee76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75c323cf92934ede9ac40b693ef87d35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1930d4032d1f422ca53caaac31b11d65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b77991ff43541b3936ee15a4fbad508":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}